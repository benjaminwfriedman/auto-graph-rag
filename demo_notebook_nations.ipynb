{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto-Graph-RAG Nations Dataset Demo\n",
    "\n",
    "This notebook demonstrates Auto-Graph-RAG using the **Nations dataset** from PyKEEN, a real-world knowledge graph of international relations between 14 countries.\n",
    "\n",
    "## Dataset Overview\n",
    "- **14 countries**: USA, USSR, China, UK, Brazil, India, Egypt, Israel, Jordan, Indonesia, Cuba, Poland, Burma, Netherlands\n",
    "- **55 relationship types**: embassy, militaryalliance, economicaid, treaties, tourism, trade, etc.\n",
    "- **1,592 relationship instances**: Real diplomatic, economic, and political relationships\n",
    "\n",
    "## What we'll build\n",
    "A question-answering system that can answer queries like:\n",
    "- \"Which countries have embassies with the USA?\"\n",
    "- \"What military alliances exist in the dataset?\"\n",
    "- \"Which countries have economic aid relationships?\"\n",
    "- \"What are the tourism relationships between countries?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Environment Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Detect environment and set working directory\n",
    "try:\n",
    "    import google.colab\n",
    "    in_colab = True\n",
    "    work_dir = Path(\"/content/auto-graph-rag/nations_demo_workspace\")\n",
    "    sys.path.append(\"/content/auto-graph-rag/src\")\n",
    "    print(\"🔍 Detected Google Colab environment\")\n",
    "except ImportError:\n",
    "    in_colab = False\n",
    "    work_dir = Path(\"./nations_demo_workspace\")\n",
    "    local_src = Path(\"./src\")\n",
    "    if local_src.exists():\n",
    "        sys.path.append(str(local_src))\n",
    "    print(\"🔍 Detected local environment\")\n",
    "\n",
    "# Create working directory\n",
    "work_dir.mkdir(exist_ok=True)\n",
    "print(f\"📁 Working directory: {work_dir.absolute()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Dependencies (if running in Colab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment and run if in Colab\n",
    "if in_colab:\n",
    "    # Install PyKEEN and Auto-Graph-RAG\n",
    "    !pip install pykeen\n",
    "    \n",
    "    # Clone and install auto-graph-rag if not already done\n",
    "    import os\n",
    "    if not os.path.exists(\"/content/auto-graph-rag\"):\n",
    "        !git clone https://github.com/benjaminwfriedman/auto-graph-rag.git /content/auto-graph-rag\n",
    "        !cd /content/auto-graph-rag && pip install -e ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Variables Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your API keys here\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"your-openai-api-key-here\"  # Required\n",
    "os.environ[\"HF_TOKEN\"] = \"your-huggingface-token-here\"      # Optional but recommended\n",
    "\n",
    "# Check environment\n",
    "has_openai = bool(os.getenv(\"OPENAI_API_KEY\")) and os.getenv(\"OPENAI_API_KEY\") != \"your-openai-api-key-here\"\n",
    "has_hf = bool(os.getenv(\"HF_TOKEN\")) and os.getenv(\"HF_TOKEN\") != \"your-huggingface-token-here\"\n",
    "\n",
    "print(f\"🔑 OpenAI API Key: {'✅ Available' if has_openai else '❌ Missing - Required for this demo'}\")\n",
    "print(f\"🤗 HuggingFace Token: {'✅ Available' if has_hf else '⚠️ Missing - Recommended for model downloads'}\")\n",
    "\n",
    "if not has_openai:\n",
    "    print(\"\\n❌ Please set your OpenAI API key above to continue with the demo.\")\n",
    "    print(\"   You can get one at: https://platform.openai.com/api-keys\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pykeen.datasets\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import Auto-Graph-RAG modules\n",
    "from auto_graph_rag.modules import (\n",
    "    GraphBuilder,\n",
    "    GraphExplorer,\n",
    "    DataGenerator,\n",
    "    ModelTrainer,\n",
    "    QueryExecutor\n",
    ")\n",
    "\n",
    "print(\"✅ All imports successful!\")\n",
    "print(\"Available modules:\")\n",
    "for module in [GraphBuilder, GraphExplorer, DataGenerator, ModelTrainer, QueryExecutor]:\n",
    "    print(f\"  - {module.__name__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load and Convert Nations Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_nations_dataset():\n",
    "    \"\"\"Load the Nations dataset from PyKEEN and convert to NetworkX.\"\"\"\n",
    "    print(\"📦 Loading Nations dataset from PyKEEN...\")\n",
    "    \n",
    "    # Load dataset\n",
    "    dataset = pykeen.datasets.Nations()\n",
    "    training = dataset.training\n",
    "    \n",
    "    print(f\"📊 Dataset Statistics:\")\n",
    "    print(f\"  - Countries: {training.num_entities}\")\n",
    "    print(f\"  - Relationship types: {training.num_relations}\")\n",
    "    print(f\"  - Total relationships: {training.num_triples}\")\n",
    "    \n",
    "    # Get mappings\n",
    "    entity_to_id = training.entity_to_id\n",
    "    relation_to_id = training.relation_to_id\n",
    "    id_to_entity = {v: k for k, v in entity_to_id.items()}\n",
    "    id_to_relation = {v: k for k, v in relation_to_id.items()}\n",
    "    \n",
    "    print(f\"\\n🌍 Countries in dataset:\")\n",
    "    countries = sorted(entity_to_id.keys())\n",
    "    for i, country in enumerate(countries):\n",
    "        if i % 5 == 0 and i > 0:\n",
    "            print()  # New line every 5 countries\n",
    "        print(f\"{country:12}\", end=\" \")\n",
    "    print()\n",
    "    \n",
    "    print(f\"\\n🔗 Top 10 relationship types:\")\n",
    "    triples = training.mapped_triples\n",
    "    relation_counts = Counter()\n",
    "    for i in range(len(triples)):\n",
    "        h, r, t = triples[i]\n",
    "        relation = id_to_relation[r.item()]\n",
    "        relation_counts[relation] += 1\n",
    "    \n",
    "    for relation, count in relation_counts.most_common(10):\n",
    "        print(f\"  - {relation:20}: {count:3d} instances\")\n",
    "    \n",
    "    # Create NetworkX graph\n",
    "    print(f\"\\n🔄 Converting to NetworkX graph...\")\n",
    "    G = nx.DiGraph()\n",
    "    \n",
    "    # Add nodes (countries) with metadata\n",
    "    for country in entity_to_id.keys():\n",
    "        G.add_node(country, type=\"Country\", name=country, region=\"Unknown\")\n",
    "    \n",
    "    # Add edges (relationships)\n",
    "    for i in range(len(triples)):\n",
    "        h, r, t = triples[i]\n",
    "        head_country = id_to_entity[h.item()]\n",
    "        relation = id_to_relation[r.item()]\n",
    "        tail_country = id_to_entity[t.item()]\n",
    "        \n",
    "        # Add edge with relation type\n",
    "        G.add_edge(head_country, tail_country, type=relation, relation=relation)\n",
    "    \n",
    "    print(f\"✅ NetworkX graph created:\")\n",
    "    print(f\"  - Nodes: {G.number_of_nodes()}\")\n",
    "    print(f\"  - Edges: {G.number_of_edges()}\")\n",
    "    print(f\"  - Average degree: {sum(dict(G.degree()).values()) / G.number_of_nodes():.1f}\")\n",
    "    \n",
    "    return G, relation_counts\n",
    "\n",
    "# Load the dataset\n",
    "nations_graph, relation_counts = load_nations_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize relationship distribution\n",
    "plt.figure(figsize=(12, 6))\n",
    "top_relations = dict(relation_counts.most_common(15))\n",
    "plt.bar(range(len(top_relations)), list(top_relations.values()))\n",
    "plt.xticks(range(len(top_relations)), list(top_relations.keys()), rotation=45, ha='right')\n",
    "plt.title('Top 15 International Relationship Types in Nations Dataset')\n",
    "plt.ylabel('Number of Instances')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Show some example relationships\n",
    "print(\"\\n💡 Example relationships:\")\n",
    "edges = list(nations_graph.edges(data=True))\n",
    "import random\n",
    "random.seed(42)\n",
    "sample_edges = random.sample(edges, min(10, len(edges)))\n",
    "\n",
    "for source, target, data in sample_edges:\n",
    "    relation = data['relation']\n",
    "    print(f\"  {source:12} --[{relation:15}]--> {target}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Build Graph Database with GraphBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize GraphBuilder\n",
    "builder = GraphBuilder()\n",
    "\n",
    "print(\"🔧 GraphBuilder Info:\")\n",
    "info = builder.get_info()\n",
    "for key, value in info.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "print(\"\\n📦 Building Nations graph database...\")\n",
    "\n",
    "# Extract node and edge labels\n",
    "node_labels = {node: data[\"type\"] for node, data in nations_graph.nodes(data=True)}\n",
    "edge_labels = {(u, v): data[\"type\"] for u, v, data in nations_graph.edges(data=True)}\n",
    "\n",
    "print(f\"🏷️ Creating labels:\")\n",
    "print(f\"  - Node types: {set(node_labels.values())}\")\n",
    "print(f\"  - Edge types: {len(set(edge_labels.values()))} unique relationship types\")\n",
    "\n",
    "# Build the database\n",
    "db_path = work_dir / \"nations_db\"\n",
    "stats = builder.build_from_networkx(\n",
    "    graph=nations_graph,\n",
    "    db_path=db_path,\n",
    "    graph_name=\"nations\",\n",
    "    node_labels=node_labels,\n",
    "    edge_labels=edge_labels\n",
    ")\n",
    "\n",
    "print(\"\\n✅ Nations graph database created!\")\n",
    "print(f\"📊 Database Statistics:\")\n",
    "for key, value in stats.items():\n",
    "    if isinstance(value, list) and len(value) > 5:\n",
    "        print(f\"  {key}: {len(value)} items (showing first 5: {value[:5]}...)\")\n",
    "    else:\n",
    "        print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Explore Schema with GraphExplorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize GraphExplorer\n",
    "if not has_openai:\n",
    "    print(\"❌ OpenAI API key required for schema exploration. Skipping this step.\")\n",
    "else:\n",
    "    explorer = GraphExplorer(llm_provider=\"openai\", llm_model=\"gpt-4\")\n",
    "    \n",
    "    print(\"🔧 GraphExplorer Info:\")\n",
    "    info = explorer.get_info()\n",
    "    for key, value in info.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "    \n",
    "    print(\"\\n🕵️ Exploring Nations graph schema...\")\n",
    "    print(\"This will analyze the international relationships using GPT-4...\")\n",
    "    \n",
    "    # Explore the database\n",
    "    schema_path = work_dir / \"nations_schema.json\"\n",
    "    schema = explorer.explore_from_db(\n",
    "        db_path=db_path,\n",
    "        max_samples=20,  # Sample more for richer analysis\n",
    "        save_schema_to=schema_path\n",
    "    )\n",
    "    \n",
    "    print(\"\\n✅ Schema exploration complete!\")\n",
    "    \n",
    "    # Display schema results\n",
    "    print(f\"\\n📋 Discovered Schema Summary:\")\n",
    "    print(f\"  {schema['summary']}\")\n",
    "    \n",
    "    print(f\"\\n🌍 Node Types: {list(schema['nodes'].keys())}\")\n",
    "    print(f\"🔗 Edge Types: {len(list(schema['edges'].keys()))} relationship types discovered\")\n",
    "    \n",
    "    # Show details for Country node type\n",
    "    if 'Country' in schema['nodes']:\n",
    "        country_info = schema['nodes']['Country']\n",
    "        print(f\"\\n🏛️ Country Node Details:\")\n",
    "        print(f\"  Description: {country_info['description']}\")\n",
    "        print(f\"  Properties: {country_info['properties']}\")\n",
    "        print(f\"  Example: {country_info['example_values']}\")\n",
    "    \n",
    "    # Show some interesting relationship types\n",
    "    print(f\"\\n🔗 Sample International Relationships:\")\n",
    "    for i, (rel_type, rel_info) in enumerate(list(schema['edges'].items())[:8]):\n",
    "        print(f\"  {i+1}. {rel_type}: {rel_info['description']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Generate Training Data with DataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize DataGenerator\n",
    "if not has_openai:\n",
    "    print(\"❌ OpenAI API key required for training data generation. Skipping this step.\")\n",
    "else:\n",
    "    generator = DataGenerator(llm_provider=\"openai\", llm_model=\"gpt-4\")\n",
    "    \n",
    "    print(\"🔧 DataGenerator Info:\")\n",
    "    info = generator.get_info()\n",
    "    for key, value in info.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "    \n",
    "    print(\"\\n📝 Generating training data for international relations...\")\n",
    "    print(\"This will create diverse question-Cypher pairs about countries and their relationships...\")\n",
    "    \n",
    "    # Generate dataset from the schema\n",
    "    dataset_path = work_dir / \"nations_dataset.jsonl\"\n",
    "    dataset = generator.generate_from_schema(\n",
    "        schema_path=schema_path,\n",
    "        num_examples=120,  # Good balance for demo\n",
    "        output_path=dataset_path,\n",
    "        complexity_distribution={\n",
    "            1: 0.25,  # Simple lookups: \"List all countries\", \"What countries exist?\"\n",
    "            2: 0.35,  # Filtered queries: \"Countries with embassies\", \"Military alliances\"\n",
    "            3: 0.25,  # Relationships: \"Which countries have diplomatic relations?\"\n",
    "            4: 0.15,  # Aggregations: \"Count of relationships by type\"\n",
    "        },\n",
    "        db_path=db_path  # For query validation\n",
    "    )\n",
    "    \n",
    "    print(\"\\n✅ Training data generated!\")\n",
    "    \n",
    "    # Analyze the dataset\n",
    "    print(f\"\\n📊 Dataset Statistics:\")\n",
    "    print(f\"  Total examples: {len(dataset)}\")\n",
    "    \n",
    "    # Complexity and intent analysis\n",
    "    complexity_counts = Counter(item.get('complexity', 0) for item in dataset)\n",
    "    intent_counts = Counter(item.get('intent', 'unknown') for item in dataset)\n",
    "    \n",
    "    print(f\"  Complexity distribution: {dict(complexity_counts)}\")\n",
    "    print(f\"  Intent types: {len(intent_counts)} different intents\")\n",
    "    \n",
    "    # Show sample examples focused on international relations\n",
    "    print(f\"\\n💡 Sample Training Examples for International Relations:\")\n",
    "    \n",
    "    # Find examples with interesting relations\n",
    "    interesting_examples = []\n",
    "    keywords = ['embassy', 'military', 'economic', 'alliance', 'tourism', 'trade', 'diplomatic']\n",
    "    \n",
    "    for example in dataset:\n",
    "        question = example.get('question', '').lower()\n",
    "        cypher = example.get('cypher', '').lower()\n",
    "        if any(keyword in question or keyword in cypher for keyword in keywords):\n",
    "            interesting_examples.append(example)\n",
    "    \n",
    "    # Show a mix of examples\n",
    "    examples_to_show = interesting_examples[:3] + dataset[:2]  # 3 interesting + 2 random\n",
    "    \n",
    "    for i, example in enumerate(examples_to_show[:5], 1):\n",
    "        print(f\"\\n  Example {i}:\")\n",
    "        print(f\"    Question: {example.get('question', 'N/A')}\")\n",
    "        cypher = example.get('cypher', 'N/A')\n",
    "        if len(cypher) > 80:\n",
    "            cypher = cypher[:77] + \"...\"\n",
    "        print(f\"    Cypher: {cypher}\")\n",
    "        print(f\"    Complexity: {example.get('complexity', 'N/A')}\")\n",
    "        print(f\"    Intent: {example.get('intent', 'N/A')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Fine-tune Model with ModelTrainer\n",
    "\n",
    "⚠️ **Note**: Model training is computationally intensive. For this demo, we'll use a small, efficient configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize ModelTrainer\n",
    "trainer = ModelTrainer()\n",
    "\n",
    "print(\"🔧 ModelTrainer Info:\")\n",
    "info = trainer.get_info()\n",
    "for key, value in info.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# Configuration for efficient training\n",
    "model_config = {\n",
    "    \"base_model\": \"meta-llama/Llama-3.2-1B-Instruct\",  # Small, efficient model\n",
    "    \"epochs\": 10,  # Reduced for demo\n",
    "    \"learning_rate\": 5e-4,\n",
    "    \"batch_size\": 4,\n",
    "    \"lora_rank\": 8,\n",
    "    \"output_dir\": str(work_dir / \"nations_model\")\n",
    "}\n",
    "\n",
    "print(f\"\\n⚙️ Training Configuration:\")\n",
    "for key, value in model_config.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "print(f\"\\n🎯 Starting model training for international relations...\")\n",
    "print(f\"Training a specialized model to understand diplomatic, economic, and political relationships!\")\n",
    "\n",
    "# Train the model\n",
    "model = trainer.train_from_file(\n",
    "    dataset_path=dataset_path,\n",
    "    model_name=model_config[\"base_model\"],\n",
    "    output_dir=Path(model_config[\"output_dir\"]),\n",
    "    epochs=model_config[\"epochs\"],\n",
    "    learning_rate=model_config[\"learning_rate\"],\n",
    "    batch_size=model_config[\"batch_size\"],\n",
    "    lora_rank=model_config[\"lora_rank\"]\n",
    ")\n",
    "\n",
    "print(\"\\n✅ Model training completed!\")\n",
    "print(f\"🎉 Nations-specialized model ready for international relations queries!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Query the International Relations Graph with QueryExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize QueryExecutor\n",
    "executor = QueryExecutor()\n",
    "\n",
    "print(\"🔧 QueryExecutor Info:\")\n",
    "info = executor.get_info()\n",
    "for key, value in info.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# Use the trained model and database\n",
    "model_path = work_dir / \"nations_model\"\n",
    "print(f\"\\n🎯 Using Assets:\")\n",
    "print(f\"  Model: {model_path} (Nations-specialized model)\")\n",
    "print(f\"  Database: {db_path} (Nations knowledge graph)\")\n",
    "\n",
    "# International relations test questions\n",
    "test_questions = [\n",
    "    \"What countries are in the dataset?\",\n",
    "    \"Which countries have embassy relationships?\",\n",
    "    \"What military alliances exist between countries?\",\n",
    "    \"Which countries have economic aid relationships?\",\n",
    "    \"What tourism relationships exist in the data?\",\n",
    "    \"How many different types of relationships are there?\",\n",
    "    \"Which countries have the most international relationships?\",\n",
    "    \"What diplomatic relationships exist between USA and other countries?\"\n",
    "]\n",
    "\n",
    "print(f\"\\n❓ Test Questions for International Relations:\")\n",
    "for i, question in enumerate(test_questions, 1):\n",
    "    print(f\"  {i}. {question}\")\n",
    "\n",
    "print(f\"\\n🤖 Query Execution with Nations-Specialized Model:\")\n",
    "print(f\"Let's see how our model handles international relations queries!\")\n",
    "\n",
    "for i, question in enumerate(test_questions, 1):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Query {i}: {question}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    result = executor.query_with_model(\n",
    "        question=question,\n",
    "        model_path=model_path,\n",
    "        db_path=db_path,\n",
    "        return_cypher=True,\n",
    "        format_results=True\n",
    "    )\n",
    "    \n",
    "    if result['success']:\n",
    "        print(f\"✅ Generated Cypher: {result['cypher']}\")\n",
    "        print(f\"📊 Results: {result['count']} rows\")\n",
    "        \n",
    "        if 'results' in result and result['results']:\n",
    "            print(f\"\\n🔍 Sample Results:\")\n",
    "            # Show more results for international relations\n",
    "            max_results = min(8, len(result['results']))\n",
    "            for j, row in enumerate(result['results'][:max_results]):\n",
    "                print(f\"    {j+1:2d}. {row}\")\n",
    "            if len(result['results']) > max_results:\n",
    "                print(f\"    ... and {len(result['results']) - max_results} more\")\n",
    "    else:\n",
    "        print(f\"❌ Error: {result['error']}\")\n",
    "    \n",
    "    print()  # Add space between queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Analysis: International Relations Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's ask some more sophisticated geopolitical questions\n",
    "advanced_questions = [\n",
    "    \"Which countries have both military and economic relationships?\",\n",
    "    \"What are the different types of diplomatic activities?\",\n",
    "    \"Which countries are most central in the international network?\",\n",
    "    \"Are there any countries with negative relationships like boycotts or accusations?\",\n",
    "    \"What cultural exchange relationships exist (books, students, tourism)?\"\n",
    "]\n",
    "\n",
    "print(\"🔬 Advanced International Relations Analysis:\")\n",
    "print(\"Let's explore deeper geopolitical patterns...\\n\")\n",
    "\n",
    "for i, question in enumerate(advanced_questions, 1):\n",
    "    print(f\"🌍 Advanced Query {i}: {question}\")\n",
    "    \n",
    "    result = executor.query_with_model(\n",
    "        question=question,\n",
    "        model_path=model_path,\n",
    "        db_path=db_path,\n",
    "        return_cypher=True,\n",
    "        format_results=True\n",
    "    )\n",
    "    \n",
    "    if result['success']:\n",
    "        print(f\"  💡 Query: {result['cypher']}\")\n",
    "        print(f\"  📊 Found: {result['count']} results\")\n",
    "        \n",
    "        if result['results']:\n",
    "            # Show top results\n",
    "            for j, row in enumerate(result['results'][:5]):\n",
    "                print(f\"     • {row}\")\n",
    "            if len(result['results']) > 5:\n",
    "                print(f\"     ... and {len(result['results']) - 5} more\")\n",
    "    else:\n",
    "        print(f\"  ❌ Error: {result['error']}\")\n",
    "    \n",
    "    print()  # Space between queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Insights\n",
    "\n",
    "🎉 **Congratulations!** You've successfully built a complete question-answering system for international relations using Auto-Graph-RAG!\n",
    "\n",
    "### What we accomplished:\n",
    "\n",
    "1. **📦 Loaded Real Data**: Used the Nations dataset with 14 countries and 55 relationship types\n",
    "2. **🏗️ Built Graph Database**: Converted international relations into a queryable Kuzu database\n",
    "3. **🔍 Schema Discovery**: Let GPT-4 understand the diplomatic, economic, and political relationships\n",
    "4. **📝 Generated Training Data**: Created 120+ question-Cypher pairs about international relations\n",
    "5. **🎯 Fine-tuned Model**: Trained Llama-3.2-1B to understand geopolitical queries\n",
    "6. **💬 Deployed QA System**: Built a natural language interface for exploring international relations\n",
    "\n",
    "### Key Insights from the Nations Dataset:\n",
    "\n",
    "- **Embassy relationships** are the most common (100 instances)\n",
    "- **Military alliances** and **economic aid** reveal geopolitical structures\n",
    "- **Cultural exchanges** through tourism, students, and book translations\n",
    "- **Diplomatic activities** like conferences and official visits\n",
    "- **Negative relationships** including boycotts and accusations\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "1. **Expand the Dataset**: Add more countries or time-series data\n",
    "2. **Custom Relationships**: Define domain-specific relationship types\n",
    "3. **Multi-modal Data**: Include geographic, economic, or demographic data\n",
    "4. **Production Deployment**: Scale for larger knowledge graphs\n",
    "\n",
    "This demonstrates how Auto-Graph-RAG can transform any knowledge graph into an intelligent QA system!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}