{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/benjaminwfriedman/auto-graph-rag/blob/make_modular/modular_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2iOO5FrcC2tX"
      },
      "source": [
        "# Auto-Graph-RAG Modular Architecture Demo\n",
        "\n",
        "This notebook demonstrates the new modular architecture of Auto-Graph-RAG, showing how each component can be used independently or composed together.\n",
        "\n",
        "## Key Benefits\n",
        "- **Independent Testing**: Test each component with known inputs\n",
        "- **Reusable Assets**: Reuse expensive operations (schemas, datasets, models)\n",
        "- **Flexible Composition**: Mix and match modules or skip steps\n",
        "- **Better Debugging**: Isolate issues to specific components\n",
        "- **Incremental Development**: Work on parts without full pipeline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "# check if \"auto-graph-rag\" repo exists - if so delete it recursivly\n",
        "if os.path.exists(\"auto-graph-rag\"):\n",
        "    shutil.rmtree(\"auto-graph-rag\")"
      ],
      "metadata": {
        "id": "HlmEvwf5DVil"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/benjaminwfriedman/auto-graph-rag.git\n",
        "!cd auto-graph-rag && git branch\n",
        "!cd auto-graph-rag && git checkout make_modular\n",
        "!cd auto-graph-rag && git pull\n",
        "!cd auto-graph-rag && pip install -e .\n"
      ],
      "metadata": {
        "id": "kMoT9IwzC5LO",
        "outputId": "e0b145f1-0215-4d54-af07-8ba9a485ee6c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'auto-graph-rag'...\n",
            "remote: Enumerating objects: 83, done.\u001b[K\n",
            "remote: Counting objects: 100% (83/83), done.\u001b[K\n",
            "remote: Compressing objects: 100% (70/70), done.\u001b[K\n",
            "remote: Total 83 (delta 14), reused 79 (delta 10), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (83/83), 464.49 KiB | 5.28 MiB/s, done.\n",
            "Resolving deltas: 100% (14/14), done.\n",
            "* \u001b[32mmain\u001b[m\n",
            "Branch 'make_modular' set up to track remote branch 'make_modular' from 'origin'.\n",
            "Switched to a new branch 'make_modular'\n",
            "Already up to date.\n",
            "Obtaining file:///content/auto-graph-rag\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.12/dist-packages (from auto-graph-rag==0.1.0) (3.5)\n",
            "Collecting kuzu>=0.6.0 (from auto-graph-rag==0.1.0)\n",
            "  Downloading kuzu-0.11.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: openai>=1.0 in /usr/local/lib/python3.12/dist-packages (from auto-graph-rag==0.1.0) (1.107.0)\n",
            "Requirement already satisfied: transformers>=4.40 in /usr/local/lib/python3.12/dist-packages (from auto-graph-rag==0.1.0) (4.56.1)\n",
            "Requirement already satisfied: peft>=0.10 in /usr/local/lib/python3.12/dist-packages (from auto-graph-rag==0.1.0) (0.17.1)\n",
            "Requirement already satisfied: datasets>=2.0 in /usr/local/lib/python3.12/dist-packages (from auto-graph-rag==0.1.0) (4.0.0)\n",
            "Requirement already satisfied: accelerate>=0.30 in /usr/local/lib/python3.12/dist-packages (from auto-graph-rag==0.1.0) (1.10.1)\n",
            "Collecting bitsandbytes>=0.40 (from auto-graph-rag==0.1.0)\n",
            "  Downloading bitsandbytes-0.47.0-py3-none-manylinux_2_24_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: pandas>=2.0 in /usr/local/lib/python3.12/dist-packages (from auto-graph-rag==0.1.0) (2.2.2)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.12/dist-packages (from auto-graph-rag==0.1.0) (2.11.7)\n",
            "Requirement already satisfied: typer>=0.12 in /usr/local/lib/python3.12/dist-packages (from auto-graph-rag==0.1.0) (0.17.4)\n",
            "Requirement already satisfied: rich>=13.0 in /usr/local/lib/python3.12/dist-packages (from auto-graph-rag==0.1.0) (13.9.4)\n",
            "Requirement already satisfied: torch>=2.0 in /usr/local/lib/python3.12/dist-packages (from auto-graph-rag==0.1.0) (2.8.0+cu126)\n",
            "Requirement already satisfied: langchain>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from auto-graph-rag==0.1.0) (0.3.27)\n",
            "Collecting langchain-openai>=0.1.0 (from auto-graph-rag==0.1.0)\n",
            "  Downloading langchain_openai-0.3.33-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: python-dotenv>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from auto-graph-rag==0.1.0) (1.1.1)\n",
            "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.12/dist-packages (from accelerate>=0.30->auto-graph-rag==0.1.0) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from accelerate>=0.30->auto-graph-rag==0.1.0) (25.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate>=0.30->auto-graph-rag==0.1.0) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from accelerate>=0.30->auto-graph-rag==0.1.0) (6.0.2)\n",
            "Requirement already satisfied: huggingface_hub>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from accelerate>=0.30->auto-graph-rag==0.1.0) (0.34.4)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from accelerate>=0.30->auto-graph-rag==0.1.0) (0.6.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0->auto-graph-rag==0.1.0) (3.19.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0->auto-graph-rag==0.1.0) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0->auto-graph-rag==0.1.0) (0.3.8)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0->auto-graph-rag==0.1.0) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0->auto-graph-rag==0.1.0) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0->auto-graph-rag==0.1.0) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0->auto-graph-rag==0.1.0) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.0->auto-graph-rag==0.1.0) (2025.3.0)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /usr/local/lib/python3.12/dist-packages (from langchain>=0.2.0->auto-graph-rag==0.1.0) (0.3.75)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain>=0.2.0->auto-graph-rag==0.1.0) (0.3.11)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.12/dist-packages (from langchain>=0.2.0->auto-graph-rag==0.1.0) (0.4.27)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain>=0.2.0->auto-graph-rag==0.1.0) (2.0.43)\n",
            "Collecting langchain-core<1.0.0,>=0.3.72 (from langchain>=0.2.0->auto-graph-rag==0.1.0)\n",
            "  Downloading langchain_core-0.3.76-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.12/dist-packages (from langchain-openai>=0.1.0->auto-graph-rag==0.1.0) (0.11.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai>=1.0->auto-graph-rag==0.1.0) (4.10.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai>=1.0->auto-graph-rag==0.1.0) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai>=1.0->auto-graph-rag==0.1.0) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai>=1.0->auto-graph-rag==0.1.0) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai>=1.0->auto-graph-rag==0.1.0) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai>=1.0->auto-graph-rag==0.1.0) (4.15.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.0->auto-graph-rag==0.1.0) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.0->auto-graph-rag==0.1.0) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.0->auto-graph-rag==0.1.0) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.0->auto-graph-rag==0.1.0) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.0->auto-graph-rag==0.1.0) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.0->auto-graph-rag==0.1.0) (0.4.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=13.0->auto-graph-rag==0.1.0) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=13.0->auto-graph-rag==0.1.0) (2.19.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->auto-graph-rag==0.1.0) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->auto-graph-rag==0.1.0) (1.13.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->auto-graph-rag==0.1.0) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->auto-graph-rag==0.1.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->auto-graph-rag==0.1.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->auto-graph-rag==0.1.0) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->auto-graph-rag==0.1.0) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->auto-graph-rag==0.1.0) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->auto-graph-rag==0.1.0) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->auto-graph-rag==0.1.0) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->auto-graph-rag==0.1.0) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->auto-graph-rag==0.1.0) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->auto-graph-rag==0.1.0) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->auto-graph-rag==0.1.0) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->auto-graph-rag==0.1.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->auto-graph-rag==0.1.0) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->auto-graph-rag==0.1.0) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->auto-graph-rag==0.1.0) (3.4.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.40->auto-graph-rag==0.1.0) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.40->auto-graph-rag==0.1.0) (0.22.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.12->auto-graph-rag==0.1.0) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.12->auto-graph-rag==0.1.0) (1.5.4)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai>=1.0->auto-graph-rag==0.1.0) (3.10)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.0->auto-graph-rag==0.1.0) (3.12.15)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai>=1.0->auto-graph-rag==0.1.0) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai>=1.0->auto-graph-rag==0.1.0) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.0->auto-graph-rag==0.1.0) (0.16.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate>=0.30->auto-graph-rag==0.1.0) (1.1.9)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain>=0.2.0->auto-graph-rag==0.1.0) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain>=0.2.0->auto-graph-rag==0.1.0) (1.33)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain>=0.2.0->auto-graph-rag==0.1.0) (3.11.3)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain>=0.2.0->auto-graph-rag==0.1.0) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain>=0.2.0->auto-graph-rag==0.1.0) (0.24.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=13.0->auto-graph-rag==0.1.0) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=2.0->auto-graph-rag==0.1.0) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets>=2.0->auto-graph-rag==0.1.0) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets>=2.0->auto-graph-rag==0.1.0) (2.5.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain>=0.2.0->auto-graph-rag==0.1.0) (3.2.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0->auto-graph-rag==0.1.0) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0->auto-graph-rag==0.1.0) (3.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.0->auto-graph-rag==0.1.0) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.0->auto-graph-rag==0.1.0) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.0->auto-graph-rag==0.1.0) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.0->auto-graph-rag==0.1.0) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.0->auto-graph-rag==0.1.0) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.0->auto-graph-rag==0.1.0) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.0->auto-graph-rag==0.1.0) (1.20.1)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain>=0.2.0->auto-graph-rag==0.1.0) (3.0.0)\n",
            "Downloading bitsandbytes-0.47.0-py3-none-manylinux_2_24_x86_64.whl (61.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.3/61.3 MB\u001b[0m \u001b[31m38.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kuzu-0.11.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (7.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m103.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_openai-0.3.33-py3-none-any.whl (74 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.3.76-py3-none-any.whl (447 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m447.5/447.5 kB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: kuzu, langchain-core, bitsandbytes, langchain-openai, auto-graph-rag\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.75\n",
            "    Uninstalling langchain-core-0.3.75:\n",
            "      Successfully uninstalled langchain-core-0.3.75\n",
            "  Running setup.py develop for auto-graph-rag\n",
            "Successfully installed auto-graph-rag-0.1.0 bitsandbytes-0.47.0 kuzu-0.11.2 langchain-core-0.3.76 langchain-openai-0.3.33\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Restart Runtime if in Colab❗"
      ],
      "metadata": {
        "id": "pkfqxU5xKA6C"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zEuAhaljC2tY"
      },
      "source": [
        "## Setup and Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "DzB7oog9C2tY",
        "outputId": "c5afdee6-17c1-4799-8b82-35a8391a3e40",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Imports successful!\n",
            "Available modules:\n",
            "  - GraphBuilder\n",
            "  - GraphExplorer\n",
            "  - DataGenerator\n",
            "  - ModelTrainer\n",
            "  - QueryExecutor\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "import networkx as nx\n",
        "from pathlib import Path\n",
        "import tempfile\n",
        "import shutil\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "# Import modular components\n",
        "from auto_graph_rag.modules import (\n",
        "    GraphBuilder,\n",
        "    GraphExplorer,\n",
        "    DataGenerator,\n",
        "    ModelTrainer,\n",
        "    QueryExecutor\n",
        ")\n",
        "\n",
        "# Original interface for comparison\n",
        "from auto_graph_rag import GraphRAG\n",
        "\n",
        "print(\"✅ Imports successful!\")\n",
        "print(\"Available modules:\")\n",
        "for module in [GraphBuilder, GraphExplorer, DataGenerator, ModelTrainer, QueryExecutor]:\n",
        "    print(f\"  - {module.__name__}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NpkgVXDJC2tZ"
      },
      "source": [
        "## Environment Setup\n",
        "\n",
        "Let's set up our working directory and check for required API keys."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# set OPENAI_API_KEY and HF_TOKEN\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"YOUR_OPENAI_API_KEY\"\n",
        "os.environ[\"HF_TOKEN\"] = \"YOUR_HF_TOKEN\""
      ],
      "metadata": {
        "id": "vhhiLsYSID8d"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "CKm58xaDC2tZ",
        "outputId": "32df558e-df6f-4e66-8241-d068b71a00d4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Detected Google Colab environment\n",
            "📁 Working directory: /content/auto-graph-rag/modular_demo_workspace\n",
            "🔑 OpenAI API Key: ✅ Available\n",
            "🤗 HuggingFace Token: ✅ Available\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "# Create working directory\n",
        "# Detect environment and set working directory\n",
        "try:\n",
        "    import google.colab\n",
        "    in_colab = True\n",
        "    work_dir = Path(\"/content/auto-graph-rag/modular_demo_workspace\")\n",
        "    sys.path.append(\"/content/auto-graph-rag/src\")\n",
        "    print(\"🔍 Detected Google Colab environment\")\n",
        "except ImportError:\n",
        "    in_colab = False\n",
        "    work_dir = Path(\"./modular_demo_workspace\")\n",
        "    local_src = Path(\"./auto-graph-rag/src\")\n",
        "    if local_src.exists():\n",
        "        sys.path.append(str(local_src))\n",
        "    print(\"🔍 Detected local environment\")\n",
        "\n",
        "print(f\"📁 Working directory: {work_dir.absolute()}\")\n",
        "\n",
        "# Check environment - require API key for full demo\n",
        "has_openai = bool(os.getenv(\"OPENAI_API_KEY\"))\n",
        "has_hf = bool(os.getenv(\"HF_TOKEN\"))\n",
        "\n",
        "print(f\"🔑 OpenAI API Key: {'✅ Available' if has_openai else '❌ Missing'}\")\n",
        "print(f\"🤗 HuggingFace Token: {'✅ Available' if has_hf else '❌ Missing (optional for some models)'}\")\n",
        "\n",
        "if not has_openai:\n",
        "    print(\"\\n❌ Error: OPENAI_API_KEY is required for this demo\")\n",
        "    print(\"Please set it with: os.environ['OPENAI_API_KEY'] = 'your-key-here'\")\n",
        "    raise ValueError(\"OPENAI_API_KEY environment variable is required\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DG66mWroC2tZ"
      },
      "source": [
        "## Step 1: Graph Builder Module\n",
        "\n",
        "The `GraphBuilder` creates Kuzu databases from NetworkX graphs or raw data. This can be used standalone without any other components."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Lr6fh6MdC2tZ",
        "outputId": "110e7d0d-a46e-4e23-dbbf-1e627a0d6ce6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 Created sample graph:\n",
            "  - Nodes: 9\n",
            "  - Edges: 9\n",
            "  - Node types: {'Project', 'Employee', 'Department'}\n",
            "  - Edge types: {'WORKED_ON', 'OWNED_BY', 'BELONGS_TO'}\n"
          ]
        }
      ],
      "source": [
        "# Create a sample company graph\n",
        "def create_sample_graph():\n",
        "    \"\"\"Create a sample company graph for demonstration.\"\"\"\n",
        "    G = nx.DiGraph()\n",
        "\n",
        "    # Add employees\n",
        "    employees = [\n",
        "        (\"emp1\", {\"name\": \"Alice Johnson\", \"department\": \"Engineering\", \"salary\": 120000, \"level\": \"Senior\"}),\n",
        "        (\"emp2\", {\"name\": \"Bob Smith\", \"department\": \"Engineering\", \"salary\": 95000, \"level\": \"Junior\"}),\n",
        "        (\"emp3\", {\"name\": \"Carol White\", \"department\": \"Marketing\", \"salary\": 85000, \"level\": \"Mid\"}),\n",
        "        (\"emp4\", {\"name\": \"David Brown\", \"department\": \"Sales\", \"salary\": 90000, \"level\": \"Senior\"}),\n",
        "    ]\n",
        "\n",
        "    for emp_id, attrs in employees:\n",
        "        G.add_node(emp_id, type=\"Employee\", **attrs)\n",
        "\n",
        "    # Add departments\n",
        "    departments = [\n",
        "        (\"dept1\", {\"name\": \"Engineering\", \"budget\": 2000000, \"head_count\": 25}),\n",
        "        (\"dept2\", {\"name\": \"Marketing\", \"budget\": 800000, \"head_count\": 10}),\n",
        "        (\"dept3\", {\"name\": \"Sales\", \"budget\": 1200000, \"head_count\": 15}),\n",
        "    ]\n",
        "\n",
        "    for dept_id, attrs in departments:\n",
        "        G.add_node(dept_id, type=\"Department\", **attrs)\n",
        "\n",
        "    # Add projects\n",
        "    projects = [\n",
        "        (\"proj1\", {\"name\": \"Alpha\", \"budget\": 500000, \"status\": \"Active\"}),\n",
        "        (\"proj2\", {\"name\": \"Beta\", \"budget\": 300000, \"status\": \"Planning\"}),\n",
        "    ]\n",
        "    for proj_id, attrs in projects:\n",
        "        G.add_node(proj_id, type=\"Project\", **attrs)\n",
        "\n",
        "    # Add relationships\n",
        "    G.add_edge(\"emp1\", \"dept1\", type=\"BELONGS_TO\", since=\"2020-01-15\")\n",
        "    G.add_edge(\"emp2\", \"dept1\", type=\"BELONGS_TO\", since=\"2023-03-01\")\n",
        "    G.add_edge(\"emp3\", \"dept2\", type=\"BELONGS_TO\", since=\"2021-06-15\")\n",
        "    G.add_edge(\"emp4\", \"dept3\", type=\"BELONGS_TO\", since=\"2019-09-01\")\n",
        "\n",
        "    G.add_edge(\"emp1\", \"proj1\", type=\"WORKED_ON\", hours=320, role=\"Lead\")\n",
        "    G.add_edge(\"emp2\", \"proj1\", type=\"WORKED_ON\", hours=480, role=\"Developer\")\n",
        "    G.add_edge(\"emp3\", \"proj2\", type=\"WORKED_ON\", hours=200, role=\"Marketing Lead\")\n",
        "\n",
        "    G.add_edge(\"proj1\", \"dept1\", type=\"OWNED_BY\")\n",
        "    G.add_edge(\"proj2\", \"dept2\", type=\"OWNED_BY\")\n",
        "\n",
        "    return G\n",
        "\n",
        "# Create the graph\n",
        "sample_graph = create_sample_graph()\n",
        "\n",
        "print(f\"📊 Created sample graph:\")\n",
        "print(f\"  - Nodes: {sample_graph.number_of_nodes()}\")\n",
        "print(f\"  - Edges: {sample_graph.number_of_edges()}\")\n",
        "print(f\"  - Node types: {set(data['type'] for _, data in sample_graph.nodes(data=True))}\")\n",
        "print(f\"  - Edge types: {set(data['type'] for _, _, data in sample_graph.edges(data=True))}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "SZk72UE0C2ta",
        "outputId": "66c70b28-204a-483c-b5d8-44057b90e6d1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔧 GraphBuilder Info:\n",
            "  name: GraphBuilder\n",
            "  version: 1.0.0\n",
            "  description: Build Kuzu graphs from NetworkX or raw data\n",
            "  inputs: {'networkx': ['graph', 'db_path', 'graph_name', 'node_labels', 'edge_labels'], 'raw_data': ['nodes', 'edges', 'db_path', 'graph_name']}\n",
            "  outputs: ['statistics', 'db_path']\n",
            "\n",
            "📦 Building graph database...\n",
            "\n",
            "✅ Graph database created!\n",
            "📊 Statistics:\n",
            "  node_tables: ['company_Employee', 'company_Department', 'company_Project']\n",
            "  edge_tables: ['company_BELONGS_TO_Employee_to_Department', 'company_WORKED_ON_Employee_to_Project', 'company_OWNED_BY_Project_to_Department']\n",
            "  total_nodes: 9\n",
            "  total_edges: 9\n",
            "  db_path: /content/auto-graph-rag/modular_demo_workspace/company_db\n",
            "  graph_name: company\n"
          ]
        }
      ],
      "source": [
        "# Initialize GraphBuilder and build database\n",
        "builder = GraphBuilder()\n",
        "\n",
        "# Show module info\n",
        "print(\"🔧 GraphBuilder Info:\")\n",
        "info = builder.get_info()\n",
        "for key, value in info.items():\n",
        "    print(f\"  {key}: {value}\")\n",
        "\n",
        "print(\"\\n📦 Building graph database...\")\n",
        "\n",
        "# Extract labels\n",
        "node_labels = {node: data[\"type\"] for node, data in sample_graph.nodes(data=True)}\n",
        "edge_labels = {(u, v): data[\"type\"] for u, v, data in sample_graph.edges(data=True)}\n",
        "\n",
        "# Build the database\n",
        "db_path = work_dir / \"company_db\"\n",
        "stats = builder.build_from_networkx(\n",
        "    graph=sample_graph,\n",
        "    db_path=db_path,\n",
        "    graph_name=\"company\",\n",
        "    node_labels=node_labels,\n",
        "    edge_labels=edge_labels\n",
        ")\n",
        "\n",
        "print(\"\\n✅ Graph database created!\")\n",
        "print(f\"📊 Statistics:\")\n",
        "for key, value in stats.items():\n",
        "    print(f\"  {key}: {value}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EwvGQatXC2ta"
      },
      "source": [
        "## Step 2: Graph Explorer Module\n",
        "\n",
        "The `GraphExplorer` analyzes an existing Kuzu database to understand its schema using LLM analysis. It can work with any Kuzu database, regardless of how it was created."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1imkKYaCC2ta"
      },
      "outputs": [],
      "source": [
        "# Initialize GraphExplorer\n",
        "explorer = GraphExplorer(llm_provider=\"openai\", llm_model=\"gpt-4\")\n",
        "\n",
        "# Show module info\n",
        "print(\"🔧 GraphExplorer Info:\")\n",
        "info = explorer.get_info()\n",
        "for key, value in info.items():\n",
        "    print(f\"  {key}: {value}\")\n",
        "\n",
        "print(\"\\n🕵️ Exploring graph schema...\")\n",
        "\n",
        "# Explore the database we just created\n",
        "schema_path = work_dir / \"company_schema.json\"\n",
        "schema = explorer.explore_from_db(\n",
        "    db_path=db_path,\n",
        "    max_samples=15,\n",
        "    save_schema_to=schema_path\n",
        ")\n",
        "\n",
        "print(\"\\n✅ Schema exploration complete!\")\n",
        "\n",
        "# Display schema results\n",
        "print(f\"\\n📋 Discovered Schema:\")\n",
        "print(f\"  Summary: {schema['summary']}\")\n",
        "print(f\"  Node Types: {list(schema['nodes'].keys())}\")\n",
        "print(f\"  Edge Types: {list(schema['edges'].keys())}\")\n",
        "\n",
        "# Show detailed info for one node type\n",
        "if 'Employee' in schema['nodes']:\n",
        "    emp_info = schema['nodes']['Employee']\n",
        "    print(f\"\\n👤 Employee Node Details:\")\n",
        "    print(f\"  Description: {emp_info['description']}\")\n",
        "    print(f\"  Properties: {emp_info['properties']}\")\n",
        "    print(f\"  Example: {emp_info['example_values']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uo0Ln0kfC2ta"
      },
      "source": [
        "## Step 3: Data Generator Module\n",
        "\n",
        "The `DataGenerator` creates training datasets from graph schemas. It can work with any schema JSON file, regardless of how it was created."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CoRAI_1cC2ta"
      },
      "outputs": [],
      "source": [
        "# Initialize DataGenerator\n",
        "generator = DataGenerator(llm_provider=\"openai\", llm_model=\"gpt-4\")\n",
        "schema_path = work_dir / \"company_schema.json\"# Show module info\n",
        "db_path = work_dir / \"company_db\"\n",
        "\n",
        "\n",
        "print(\"🔧 DataGenerator Info:\")\n",
        "info = generator.get_info()\n",
        "for key, value in info.items():\n",
        "    print(f\"  {key}: {value}\")\n",
        "\n",
        "print(\"\\n📝 Generating training data...\")\n",
        "\n",
        "# Generate dataset from the schema we created\n",
        "dataset_path = work_dir / \"company_dataset.jsonl\"\n",
        "dataset = generator.generate_from_schema(\n",
        "    schema_path=schema_path,\n",
        "    num_examples=100,  # Small number for demo\n",
        "    output_path=dataset_path,\n",
        "    complexity_distribution={\n",
        "        1: 0.3,  # Simple lookups\n",
        "        2: 0.3,  # Filtered queries\n",
        "        3: 0.2,  # Relationships\n",
        "        4: 0.2,  # Aggregations\n",
        "    },\n",
        "    db_path=db_path  # For validation\n",
        ")\n",
        "\n",
        "print(\"\\n✅ Training data generated!\")\n",
        "\n",
        "# Show dataset statistics\n",
        "print(f\"\\n📊 Dataset Statistics:\")\n",
        "print(f\"  Total examples: {len(dataset)}\")\n",
        "\n",
        "# Analyze complexity distribution\n",
        "complexity_counts = {}\n",
        "intent_counts = {}\n",
        "for item in dataset:\n",
        "    complexity = item.get('complexity', 0)\n",
        "    intent = item.get('intent', 'unknown')\n",
        "    complexity_counts[complexity] = complexity_counts.get(complexity, 0) + 1\n",
        "    intent_counts[intent] = intent_counts.get(intent, 0) + 1\n",
        "\n",
        "print(f\"  Complexity distribution: {complexity_counts}\")\n",
        "print(f\"  Intent distribution: {intent_counts}\")\n",
        "\n",
        "# Show sample examples\n",
        "print(f\"\\n💡 Sample Training Examples:\")\n",
        "for i, example in enumerate(dataset[:3], 1):\n",
        "    print(f\"\\n  Example {i}:\")\n",
        "    print(f\"    Question: {example.get('question', 'N/A')}\")\n",
        "    print(f\"    Cypher: {example.get('cypher', 'N/A')[:80]}...\")\n",
        "    print(f\"    Complexity: {example.get('complexity', 'N/A')}\")\n",
        "    print(f\"    Intent: {example.get('intent', 'N/A')}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LSKu4-lMC2ta"
      },
      "source": [
        "## Step 4: Model Trainer Module\n",
        "\n",
        "The `ModelTrainer` fine-tunes language models on training datasets. It can work with any dataset file, regardless of how it was created.\n",
        "\n",
        "**Note**: Model training is computationally expensive and time-consuming. In this demo, we'll show the setup but skip the actual training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "scrolled": true,
        "id": "I8GTbJNzC2ta",
        "outputId": "0b8f99a8-3548-43c7-8ce7-579366219283",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "bba4ca273999452aaa3a02680d37c7f1",
            "0b01f186cf0041a7bc4df200ac17f593",
            "b1497594122b4849ade75ffa7252f960",
            "ef354398fb8d4bfa9516fe94bd435543",
            "6e3c2a2dbb234820a75c66bbad998f87",
            "a4f258213f614673875edead76fb61f7",
            "cb30f32a67ce4069b4417466223acb03",
            "bfb4a8c2816840ad88b0e070f400e473",
            "61a3ba965a204a4696ddeec34521c93d",
            "903e8a9adc1148009e41f69639aa52c5",
            "45059df42ff54b6294606e43a50c4870",
            "c89f1c4c79224eafb88dc0c982515ee4",
            "f6f514fbbe5f4ca9bdc6474099d62038",
            "a4f4d73651fe48aeb7a473f984ad63b6",
            "91a9fdb19e6a4f3290e86eee93fdf186",
            "ab3105cf86b14bd9a9d60a1f5e19058b",
            "0e7c6a4de01b47d9a2c1d7b4cce496df",
            "322a41abae784edf9cd0cf9d74e351fa",
            "d7c38d7b34844469a5bef70eeac2bf76",
            "bfc9c19c996544c18215dfd3335426ed",
            "74166534f1514fddbbf5a3ad3edc7038",
            "340a020e7d254662b7b2d13b76b19a31"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔧 ModelTrainer Info:\n",
            "  name: ModelTrainer\n",
            "  version: 1.0.0\n",
            "  description: Fine-tune models on graph query datasets\n",
            "  inputs: {'from_file': ['dataset_path', 'model_name', 'output_dir', 'epochs', 'learning_rate', 'batch_size', 'lora_rank'], 'from_data': ['dataset', 'model_name', 'output_dir', 'epochs', 'learning_rate', 'batch_size', 'lora_rank']}\n",
            "  outputs: ['model', 'training_stats', 'model_path']\n",
            "\n",
            "⚙️ Training Configuration:\n",
            "  dataset_path: /content/auto-graph-rag/modular_demo_workspace/company_dataset.jsonl\n",
            "  base_model: meta-llama/Llama-3.2-1B-Instruct\n",
            "  epochs: 15\n",
            "  learning_rate: 0.0005\n",
            "  batch_size: 4\n",
            "  lora_rank: 8\n",
            "  output_dir: /content/auto-graph-rag/modular_demo_workspace/company_model\n",
            "\n",
            "🎯 Model Training:\n",
            "trainable params: 5,636,096 || all params: 1,241,450,496 || trainable%: 0.4540\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/90 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bba4ca273999452aaa3a02680d37c7f1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/10 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c89f1c4c79224eafb88dc0c982515ee4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='90' max='90' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [90/90 03:18, Epoch 15/15]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>3.773100</td>\n",
              "      <td>3.819455</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>3.526300</td>\n",
              "      <td>3.327176</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>2.611000</td>\n",
              "      <td>2.447629</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1.737900</td>\n",
              "      <td>1.667299</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>1.025100</td>\n",
              "      <td>1.036484</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.728700</td>\n",
              "      <td>0.784171</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>0.603600</td>\n",
              "      <td>0.654393</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.572900</td>\n",
              "      <td>0.606400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45</td>\n",
              "      <td>0.545300</td>\n",
              "      <td>0.553526</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.429900</td>\n",
              "      <td>0.582164</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>55</td>\n",
              "      <td>0.407000</td>\n",
              "      <td>0.532357</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>0.350700</td>\n",
              "      <td>0.478101</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>65</td>\n",
              "      <td>0.245100</td>\n",
              "      <td>0.407105</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>0.176800</td>\n",
              "      <td>0.370884</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>0.165400</td>\n",
              "      <td>0.383546</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>0.142700</td>\n",
              "      <td>0.408261</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>85</td>\n",
              "      <td>0.112200</td>\n",
              "      <td>0.348774</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>0.152800</td>\n",
              "      <td>0.354939</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Initialize ModelTrainer\n",
        "trainer = ModelTrainer()\n",
        "\n",
        "\n",
        "# Show module info\n",
        "print(\"🔧 ModelTrainer Info:\")\n",
        "info = trainer.get_info()\n",
        "for key, value in info.items():\n",
        "    print(f\"  {key}: {value}\")\n",
        "\n",
        "# Show training configuration\n",
        "print(\"\\n⚙️ Training Configuration:\")\n",
        "dataset_path = work_dir / \"company_dataset.jsonl\"\n",
        "training_config = {\n",
        "    \"dataset_path\":dataset_path,\n",
        "    \"base_model\": \"meta-llama/Llama-3.2-1B-Instruct\",\n",
        "    \"epochs\": 15,\n",
        "    \"learning_rate\": 5e-4,\n",
        "    \"batch_size\": 4,\n",
        "    \"lora_rank\": 8,\n",
        "    \"output_dir\": str(work_dir / \"company_model\")\n",
        "}\n",
        "\n",
        "for key, value in training_config.items():\n",
        "    print(f\"  {key}: {value}\")\n",
        "\n",
        "print(\"\\n🎯 Model Training:\")\n",
        "\n",
        "model = trainer.train_from_file(\n",
        "    dataset_path=Path(training_config['dataset_path']),\n",
        "    model_name=training_config['base_model'],\n",
        "    output_dir=Path(training_config['output_dir']),\n",
        "    epochs=training_config['epochs'],\n",
        "    learning_rate=training_config['learning_rate'],\n",
        "    batch_size=training_config['batch_size'],\n",
        "    lora_rank=training_config['lora_rank']\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ccv38t9GC2ta"
      },
      "source": [
        "## Step 5: Query Executor Module\n",
        "\n",
        "The `QueryExecutor` executes natural language queries using fine-tuned models and graph databases. It can work with any trained model and database combination.\n",
        "\n",
        "**This step uses the actual trained model from Step 4 and the database from Step 1, demonstrating how assets can be reused across modules.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "yRh8j3ZgC2ta",
        "outputId": "358b8bd9-e346-4775-d430-8c91f05aa3c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:auto_graph_rag.modules.query_executor:Could not detect model name, using default\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔧 QueryExecutor Info:\n",
            "  name: QueryExecutor\n",
            "  version: 1.0.0\n",
            "  description: Execute queries with fine-tuned models\n",
            "  inputs: {'with_paths': ['question', 'model_path', 'db_path', 'return_cypher', 'format_results'], 'with_instances': ['question', 'model', 'kuzu_adapter', 'return_cypher', 'format_results']}\n",
            "  outputs: ['success', 'cypher', 'results', 'count', 'error']\n",
            "\n",
            "🎯 Using Assets from Previous Steps:\n",
            "  Model: /content/auto-graph-rag/modular_demo_workspace/company_model (from Step 4)\n",
            "  Database: /content/auto-graph-rag/modular_demo_workspace/company_db (from Step 1)\n",
            "\n",
            "❓ Test Questions:\n",
            "  1. Who are all the employees?\n",
            "  2. Which employees work in Engineering?\n",
            "  3. What projects has Alice Johnson worked on?\n",
            "  4. What is the average salary by department?\n",
            "  5. Which departments have the highest budgets?\n",
            "\n",
            "🤖 Query Execution with Trained Model:\n",
            "\n",
            "  Query 1: Who are all the employees?\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[3m Who are all the \u001b[0m\n",
              "\u001b[3m   employees?    \u001b[0m\n",
              "┏━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1me.name       \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━┩\n",
              "│ Alice Johnson │\n",
              "│ Bob Smith     │\n",
              "│ Carol White   │\n",
              "│ David Brown   │\n",
              "└───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\"> Who are all the </span>\n",
              "<span style=\"font-style: italic\">   employees?    </span>\n",
              "┏━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> e.name        </span>┃\n",
              "┡━━━━━━━━━━━━━━━┩\n",
              "│ Alice Johnson │\n",
              "│ Bob Smith     │\n",
              "│ Carol White   │\n",
              "│ David Brown   │\n",
              "└───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:auto_graph_rag.modules.query_executor:Could not detect model name, using default\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    ✅ Generated Cypher: MATCH (e:company_Employee) RETURN e.name\n",
            "    📊 Results: 4 rows\n",
            "      Row 1: {'e.name': 'Alice Johnson'}\n",
            "      Row 2: {'e.name': 'Bob Smith'}\n",
            "      ... and 2 more rows\n",
            "\n",
            "  Query 2: Which employees work in Engineering?\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[3m Which employees \u001b[0m\n",
              "\u001b[3m     work in     \u001b[0m\n",
              "\u001b[3m  Engineering?   \u001b[0m\n",
              "┏━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1me.name       \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━┩\n",
              "│ Alice Johnson │\n",
              "│ Bob Smith     │\n",
              "└───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\"> Which employees </span>\n",
              "<span style=\"font-style: italic\">     work in     </span>\n",
              "<span style=\"font-style: italic\">  Engineering?   </span>\n",
              "┏━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> e.name        </span>┃\n",
              "┡━━━━━━━━━━━━━━━┩\n",
              "│ Alice Johnson │\n",
              "│ Bob Smith     │\n",
              "└───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:auto_graph_rag.modules.query_executor:Could not detect model name, using default\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    ✅ Generated Cypher: MATCH (e:company_Employee)-[:company_BELONGS_TO_Employee_to_Department]->(d:company_Department) WHERE d.name = 'Engineering' RETURN e.name\n",
            "    📊 Results: 2 rows\n",
            "      Row 1: {'e.name': 'Alice Johnson'}\n",
            "      Row 2: {'e.name': 'Bob Smith'}\n",
            "\n",
            "  Query 3: What projects has Alice Johnson worked on?\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[3m   What   \u001b[0m\n",
              "\u001b[3m projects \u001b[0m\n",
              "\u001b[3mhas Alice \u001b[0m\n",
              "\u001b[3m Johnson  \u001b[0m\n",
              "\u001b[3mworked on?\u001b[0m\n",
              "┏━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mp.name\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━┩\n",
              "│ Alpha  │\n",
              "└────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">   What   </span>\n",
              "<span style=\"font-style: italic\"> projects </span>\n",
              "<span style=\"font-style: italic\">has Alice </span>\n",
              "<span style=\"font-style: italic\"> Johnson  </span>\n",
              "<span style=\"font-style: italic\">worked on?</span>\n",
              "┏━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> p.name </span>┃\n",
              "┡━━━━━━━━┩\n",
              "│ Alpha  │\n",
              "└────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:auto_graph_rag.modules.query_executor:Could not detect model name, using default\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    ✅ Generated Cypher: MATCH (e:company_Employee {name:'Alice Johnson'})-[:company_WORKED_ON_Employee_to_Project]->(p:company_Project) RETURN p.name\n",
            "    📊 Results: 1 rows\n",
            "      Row 1: {'p.name': 'Alpha'}\n",
            "\n",
            "  Query 4: What is the average salary by department?\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[3m  What is the average salary by   \u001b[0m\n",
              "\u001b[3m           department?            \u001b[0m\n",
              "┏━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mAverageSalary\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mDepartmentName\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━┩\n",
              "│ 90000.0       │ Sales          │\n",
              "│ 85000.0       │ Marketing      │\n",
              "│ 107500.0      │ Engineering    │\n",
              "└───────────────┴────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">  What is the average salary by   </span>\n",
              "<span style=\"font-style: italic\">           department?            </span>\n",
              "┏━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> AverageSalary </span>┃<span style=\"font-weight: bold\"> DepartmentName </span>┃\n",
              "┡━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━┩\n",
              "│ 90000.0       │ Sales          │\n",
              "│ 85000.0       │ Marketing      │\n",
              "│ 107500.0      │ Engineering    │\n",
              "└───────────────┴────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:auto_graph_rag.modules.query_executor:Could not detect model name, using default\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    ✅ Generated Cypher: MATCH (e:company_Employee)-[:company_BELONGS_TO_Employee_to_Department]->(d:company_Department) RETURN AVG(e.salary) as AverageSalary, d.name as DepartmentName\n",
            "    📊 Results: 3 rows\n",
            "      Row 1: {'AverageSalary': 90000.0, 'DepartmentName': 'Sales'}\n",
            "      Row 2: {'AverageSalary': 85000.0, 'DepartmentName': 'Marketing'}\n",
            "      ... and 1 more rows\n",
            "\n",
            "  Query 5: Which departments have the highest budgets?\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[3m     Which     \u001b[0m\n",
              "\u001b[3m  departments  \u001b[0m\n",
              "\u001b[3m   have the    \u001b[0m\n",
              "\u001b[3m    highest    \u001b[0m\n",
              "\u001b[3m   budgets?    \u001b[0m\n",
              "┏━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1md.name     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━┩\n",
              "│ Engineering │\n",
              "│ Sales       │\n",
              "│ Marketing   │\n",
              "└─────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">     Which     </span>\n",
              "<span style=\"font-style: italic\">  departments  </span>\n",
              "<span style=\"font-style: italic\">   have the    </span>\n",
              "<span style=\"font-style: italic\">    highest    </span>\n",
              "<span style=\"font-style: italic\">   budgets?    </span>\n",
              "┏━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> d.name      </span>┃\n",
              "┡━━━━━━━━━━━━━┩\n",
              "│ Engineering │\n",
              "│ Sales       │\n",
              "│ Marketing   │\n",
              "└─────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    ✅ Generated Cypher: MATCH (d:company_Department) RETURN d.name ORDER BY d.budget DESC LIMIT 5\n",
            "    📊 Results: 3 rows\n",
            "      Row 1: {'d.name': 'Engineering'}\n",
            "      Row 2: {'d.name': 'Sales'}\n",
            "      ... and 1 more rows\n"
          ]
        }
      ],
      "source": [
        "# Initialize QueryExecutor\n",
        "executor = QueryExecutor()\n",
        "\n",
        "# Use the trained model from Step 4 and database from Step 1\n",
        "model_path = work_dir / \"company_model\"  # From Step 4 ModelTrainer\n",
        "db_path = work_dir / \"company_db\"        # From Step 1 GraphBuilder\n",
        "\n",
        "print(\"🔧 QueryExecutor Info:\")\n",
        "info = executor.get_info()\n",
        "for key, value in info.items():\n",
        "    print(f\"  {key}: {value}\")\n",
        "\n",
        "print(f\"\\n🎯 Using Assets from Previous Steps:\")\n",
        "print(f\"  Model: {model_path} (from Step 4)\")\n",
        "print(f\"  Database: {db_path} (from Step 1)\")\n",
        "\n",
        "# Test questions we'd like to ask\n",
        "test_questions = [\n",
        "    \"Who are all the employees?\",\n",
        "    \"Which employees work in Engineering?\",\n",
        "    \"What projects has Alice Johnson worked on?\",\n",
        "    \"What is the average salary by department?\",\n",
        "    \"Which departments have the highest budgets?\"\n",
        "]\n",
        "\n",
        "print(\"\\n❓ Test Questions:\")\n",
        "for i, question in enumerate(test_questions, 1):\n",
        "    print(f\"  {i}. {question}\")\n",
        "\n",
        "print(\"\\n🤖 Query Execution with Trained Model:\")\n",
        "for i, question in enumerate(test_questions, 1):\n",
        "    print(f\"\\n  Query {i}: {question}\")\n",
        "\n",
        "    result = executor.query_with_model(\n",
        "        question=question,\n",
        "        model_path=Path(model_path),\n",
        "        db_path=Path(db_path),\n",
        "        return_cypher=True,\n",
        "        format_results=True\n",
        "    )\n",
        "\n",
        "    if result['success']:\n",
        "        print(f\"    ✅ Generated Cypher: {result['cypher']}\")\n",
        "        print(f\"    📊 Results: {result['count']} rows\")\n",
        "        if 'results' in result and result['results']:\n",
        "            # Show first few results\n",
        "            for j, row in enumerate(result['results'][:2]):\n",
        "                print(f\"      Row {j+1}: {row}\")\n",
        "            if len(result['results']) > 2:\n",
        "                print(f\"      ... and {len(result['results']) - 2} more rows\")\n",
        "    else:\n",
        "        print(f\"    ❌ Error: {result['error']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tIhRh95tC2tb"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "bba4ca273999452aaa3a02680d37c7f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0b01f186cf0041a7bc4df200ac17f593",
              "IPY_MODEL_b1497594122b4849ade75ffa7252f960",
              "IPY_MODEL_ef354398fb8d4bfa9516fe94bd435543"
            ],
            "layout": "IPY_MODEL_6e3c2a2dbb234820a75c66bbad998f87"
          }
        },
        "0b01f186cf0041a7bc4df200ac17f593": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a4f258213f614673875edead76fb61f7",
            "placeholder": "​",
            "style": "IPY_MODEL_cb30f32a67ce4069b4417466223acb03",
            "value": "Map: 100%"
          }
        },
        "b1497594122b4849ade75ffa7252f960": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bfb4a8c2816840ad88b0e070f400e473",
            "max": 90,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_61a3ba965a204a4696ddeec34521c93d",
            "value": 90
          }
        },
        "ef354398fb8d4bfa9516fe94bd435543": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_903e8a9adc1148009e41f69639aa52c5",
            "placeholder": "​",
            "style": "IPY_MODEL_45059df42ff54b6294606e43a50c4870",
            "value": " 90/90 [00:00&lt;00:00, 2304.55 examples/s]"
          }
        },
        "6e3c2a2dbb234820a75c66bbad998f87": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4f258213f614673875edead76fb61f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb30f32a67ce4069b4417466223acb03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bfb4a8c2816840ad88b0e070f400e473": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61a3ba965a204a4696ddeec34521c93d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "903e8a9adc1148009e41f69639aa52c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45059df42ff54b6294606e43a50c4870": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c89f1c4c79224eafb88dc0c982515ee4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f6f514fbbe5f4ca9bdc6474099d62038",
              "IPY_MODEL_a4f4d73651fe48aeb7a473f984ad63b6",
              "IPY_MODEL_91a9fdb19e6a4f3290e86eee93fdf186"
            ],
            "layout": "IPY_MODEL_ab3105cf86b14bd9a9d60a1f5e19058b"
          }
        },
        "f6f514fbbe5f4ca9bdc6474099d62038": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0e7c6a4de01b47d9a2c1d7b4cce496df",
            "placeholder": "​",
            "style": "IPY_MODEL_322a41abae784edf9cd0cf9d74e351fa",
            "value": "Map: 100%"
          }
        },
        "a4f4d73651fe48aeb7a473f984ad63b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d7c38d7b34844469a5bef70eeac2bf76",
            "max": 10,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bfc9c19c996544c18215dfd3335426ed",
            "value": 10
          }
        },
        "91a9fdb19e6a4f3290e86eee93fdf186": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_74166534f1514fddbbf5a3ad3edc7038",
            "placeholder": "​",
            "style": "IPY_MODEL_340a020e7d254662b7b2d13b76b19a31",
            "value": " 10/10 [00:00&lt;00:00, 560.77 examples/s]"
          }
        },
        "ab3105cf86b14bd9a9d60a1f5e19058b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e7c6a4de01b47d9a2c1d7b4cce496df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "322a41abae784edf9cd0cf9d74e351fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d7c38d7b34844469a5bef70eeac2bf76": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bfc9c19c996544c18215dfd3335426ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "74166534f1514fddbbf5a3ad3edc7038": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "340a020e7d254662b7b2d13b76b19a31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}