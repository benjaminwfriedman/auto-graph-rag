{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto-Graph-RAG Modular Architecture Demo\n",
    "\n",
    "This notebook demonstrates the new modular architecture of Auto-Graph-RAG, showing how each component can be used independently or composed together.\n",
    "\n",
    "## Key Benefits\n",
    "- **Independent Testing**: Test each component with known inputs\n",
    "- **Reusable Assets**: Reuse expensive operations (schemas, datasets, models)\n",
    "- **Flexible Composition**: Mix and match modules or skip steps\n",
    "- **Better Debugging**: Isolate issues to specific components\n",
    "- **Incremental Development**: Work on parts without full pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Imports successful!\n",
      "Available modules:\n",
      "  - GraphBuilder\n",
      "  - GraphExplorer\n",
      "  - DataGenerator\n",
      "  - ModelTrainer\n",
      "  - QueryExecutor\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import networkx as nx\n",
    "from pathlib import Path\n",
    "import tempfile\n",
    "import shutil\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Import modular components\n",
    "from auto_graph_rag.modules import (\n",
    "    GraphBuilder,\n",
    "    GraphExplorer, \n",
    "    DataGenerator,\n",
    "    ModelTrainer,\n",
    "    QueryExecutor\n",
    ")\n",
    "\n",
    "# Original interface for comparison\n",
    "from auto_graph_rag import GraphRAG\n",
    "\n",
    "print(\"‚úÖ Imports successful!\")\n",
    "print(\"Available modules:\")\n",
    "for module in [GraphBuilder, GraphExplorer, DataGenerator, ModelTrainer, QueryExecutor]:\n",
    "    print(f\"  - {module.__name__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "\n",
    "Let's set up our working directory and check for required API keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Working directory: /Users/benjaminfriedman/repos/auto-graph-rag/modular_demo_workspace\n",
      "üîë OpenAI API Key: ‚úÖ Available\n",
      "ü§ó HuggingFace Token: ‚úÖ Available\n"
     ]
    }
   ],
   "source": [
    "# Create working directory\n",
    "work_dir = Path(\"./modular_demo_workspace\")\n",
    "work_dir.mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"üìÅ Working directory: {work_dir.absolute()}\")\n",
    "\n",
    "# Check environment - require API key for full demo\n",
    "has_openai = bool(os.getenv(\"OPENAI_API_KEY\"))\n",
    "has_hf = bool(os.getenv(\"HF_TOKEN\"))\n",
    "\n",
    "print(f\"üîë OpenAI API Key: {'‚úÖ Available' if has_openai else '‚ùå Missing'}\")\n",
    "print(f\"ü§ó HuggingFace Token: {'‚úÖ Available' if has_hf else '‚ùå Missing (optional for some models)'}\")\n",
    "\n",
    "if not has_openai:\n",
    "    print(\"\\n‚ùå Error: OPENAI_API_KEY is required for this demo\")\n",
    "    print(\"Please set it with: os.environ['OPENAI_API_KEY'] = 'your-key-here'\")\n",
    "    raise ValueError(\"OPENAI_API_KEY environment variable is required\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Graph Builder Module\n",
    "\n",
    "The `GraphBuilder` creates Kuzu databases from NetworkX graphs or raw data. This can be used standalone without any other components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Created sample graph:\n",
      "  - Nodes: 9\n",
      "  - Edges: 9\n",
      "  - Node types: {'Project', 'Department', 'Employee'}\n",
      "  - Edge types: {'BELONGS_TO', 'WORKED_ON', 'OWNED_BY'}\n"
     ]
    }
   ],
   "source": [
    "# Create a sample company graph\n",
    "def create_sample_graph():\n",
    "    \"\"\"Create a sample company graph for demonstration.\"\"\"\n",
    "    G = nx.DiGraph()\n",
    "    \n",
    "    # Add employees\n",
    "    employees = [\n",
    "        (\"emp1\", {\"name\": \"Alice Johnson\", \"department\": \"Engineering\", \"salary\": 120000, \"level\": \"Senior\"}),\n",
    "        (\"emp2\", {\"name\": \"Bob Smith\", \"department\": \"Engineering\", \"salary\": 95000, \"level\": \"Junior\"}),\n",
    "        (\"emp3\", {\"name\": \"Carol White\", \"department\": \"Marketing\", \"salary\": 85000, \"level\": \"Mid\"}),\n",
    "        (\"emp4\", {\"name\": \"David Brown\", \"department\": \"Sales\", \"salary\": 90000, \"level\": \"Senior\"}),\n",
    "    ]\n",
    "    \n",
    "    for emp_id, attrs in employees:\n",
    "        G.add_node(emp_id, type=\"Employee\", **attrs)\n",
    "    \n",
    "    # Add departments\n",
    "    departments = [\n",
    "        (\"dept1\", {\"name\": \"Engineering\", \"budget\": 2000000, \"head_count\": 25}),\n",
    "        (\"dept2\", {\"name\": \"Marketing\", \"budget\": 800000, \"head_count\": 10}),\n",
    "        (\"dept3\", {\"name\": \"Sales\", \"budget\": 1200000, \"head_count\": 15}),\n",
    "    ]\n",
    "    \n",
    "    for dept_id, attrs in departments:\n",
    "        G.add_node(dept_id, type=\"Department\", **attrs)\n",
    "    \n",
    "    # Add projects\n",
    "    projects = [\n",
    "        (\"proj1\", {\"name\": \"Alpha\", \"budget\": 500000, \"status\": \"Active\"}),\n",
    "        (\"proj2\", {\"name\": \"Beta\", \"budget\": 300000, \"status\": \"Planning\"}),\n",
    "    ]\n",
    "    for proj_id, attrs in projects:\n",
    "        G.add_node(proj_id, type=\"Project\", **attrs)\n",
    "    \n",
    "    # Add relationships\n",
    "    G.add_edge(\"emp1\", \"dept1\", type=\"BELONGS_TO\", since=\"2020-01-15\")\n",
    "    G.add_edge(\"emp2\", \"dept1\", type=\"BELONGS_TO\", since=\"2023-03-01\")\n",
    "    G.add_edge(\"emp3\", \"dept2\", type=\"BELONGS_TO\", since=\"2021-06-15\")\n",
    "    G.add_edge(\"emp4\", \"dept3\", type=\"BELONGS_TO\", since=\"2019-09-01\")\n",
    "    \n",
    "    G.add_edge(\"emp1\", \"proj1\", type=\"WORKED_ON\", hours=320, role=\"Lead\")\n",
    "    G.add_edge(\"emp2\", \"proj1\", type=\"WORKED_ON\", hours=480, role=\"Developer\")\n",
    "    G.add_edge(\"emp3\", \"proj2\", type=\"WORKED_ON\", hours=200, role=\"Marketing Lead\")\n",
    "    \n",
    "    G.add_edge(\"proj1\", \"dept1\", type=\"OWNED_BY\")\n",
    "    G.add_edge(\"proj2\", \"dept2\", type=\"OWNED_BY\")\n",
    "    \n",
    "    return G\n",
    "\n",
    "# Create the graph\n",
    "sample_graph = create_sample_graph()\n",
    "\n",
    "print(f\"üìä Created sample graph:\")\n",
    "print(f\"  - Nodes: {sample_graph.number_of_nodes()}\")\n",
    "print(f\"  - Edges: {sample_graph.number_of_edges()}\")\n",
    "print(f\"  - Node types: {set(data['type'] for _, data in sample_graph.nodes(data=True))}\")\n",
    "print(f\"  - Edge types: {set(data['type'] for _, _, data in sample_graph.edges(data=True))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß GraphBuilder Info:\n",
      "  name: GraphBuilder\n",
      "  version: 1.0.0\n",
      "  description: Build Kuzu graphs from NetworkX or raw data\n",
      "  inputs: {'networkx': ['graph', 'db_path', 'graph_name', 'node_labels', 'edge_labels'], 'raw_data': ['nodes', 'edges', 'db_path', 'graph_name']}\n",
      "  outputs: ['statistics', 'db_path']\n",
      "\n",
      "üì¶ Building graph database...\n",
      "\n",
      "‚úÖ Graph database created!\n",
      "üìä Statistics:\n",
      "  node_tables: ['company_Employee', 'company_Department', 'company_Project']\n",
      "  edge_tables: ['company_BELONGS_TO_Employee_to_Department', 'company_WORKED_ON_Employee_to_Project', 'company_OWNED_BY_Project_to_Department']\n",
      "  total_nodes: 9\n",
      "  total_edges: 9\n",
      "  db_path: modular_demo_workspace/company_db\n",
      "  graph_name: company\n"
     ]
    }
   ],
   "source": [
    "# Initialize GraphBuilder and build database\n",
    "builder = GraphBuilder()\n",
    "\n",
    "# Show module info\n",
    "print(\"üîß GraphBuilder Info:\")\n",
    "info = builder.get_info()\n",
    "for key, value in info.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "print(\"\\nüì¶ Building graph database...\")\n",
    "\n",
    "# Extract labels\n",
    "node_labels = {node: data[\"type\"] for node, data in sample_graph.nodes(data=True)}\n",
    "edge_labels = {(u, v): data[\"type\"] for u, v, data in sample_graph.edges(data=True)}\n",
    "\n",
    "# Build the database\n",
    "db_path = work_dir / \"company_db\"\n",
    "stats = builder.build_from_networkx(\n",
    "    graph=sample_graph,\n",
    "    db_path=db_path,\n",
    "    graph_name=\"company\",\n",
    "    node_labels=node_labels,\n",
    "    edge_labels=edge_labels\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ Graph database created!\")\n",
    "print(f\"üìä Statistics:\")\n",
    "for key, value in stats.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Graph Explorer Module\n",
    "\n",
    "The `GraphExplorer` analyzes an existing Kuzu database to understand its schema using LLM analysis. It can work with any Kuzu database, regardless of how it was created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß GraphExplorer Info:\n",
      "  name: GraphExplorer\n",
      "  version: 1.0.0\n",
      "  description: Explore and understand graph schemas using LLM\n",
      "  inputs: {'from_db': ['db_path', 'max_samples', 'save_schema_to'], 'from_adapter': ['kuzu_adapter', 'max_samples', 'save_schema_to']}\n",
      "  outputs: ['schema', 'summary', 'node_types', 'edge_types']\n",
      "\n",
      "üïµÔ∏è Exploring graph schema...\n",
      "DEBUG: DB schema has 3 node tables, 3 edge tables\n",
      "DEBUG: Sampled 6 table groups\n",
      "DEBUG: Total sample items: 18\n",
      "DEBUG: Schema conversion - nodes: ['company_Employee', 'company_Department', 'company_Project']\n",
      "DEBUG: Schema conversion - edges: ['company_WORKED_ON_Employee_to_Project', 'company_BELONGS_TO_Employee_to_Department', 'company_OWNED_BY_Project_to_Department']\n",
      "\n",
      "‚úÖ Schema exploration complete!\n",
      "\n",
      "üìã Discovered Schema:\n",
      "  Summary: This graph represents the structure of a company, including its employees, departments, and projects. It captures the relationships between these entities, such as which employees work on which projects, which employees belong to which departments, and which departments own which projects.\n",
      "  Node Types: ['company_Employee', 'company_Department', 'company_Project']\n",
      "  Edge Types: ['company_WORKED_ON_Employee_to_Project', 'company_BELONGS_TO_Employee_to_Department', 'company_OWNED_BY_Project_to_Department']\n"
     ]
    }
   ],
   "source": [
    "# Initialize GraphExplorer \n",
    "explorer = GraphExplorer(llm_provider=\"openai\", llm_model=\"gpt-4\")\n",
    "\n",
    "# Show module info\n",
    "print(\"üîß GraphExplorer Info:\")\n",
    "info = explorer.get_info()\n",
    "for key, value in info.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "print(\"\\nüïµÔ∏è Exploring graph schema...\")\n",
    "\n",
    "# Explore the database we just created\n",
    "schema_path = work_dir / \"company_schema.json\"\n",
    "schema = explorer.explore_from_db(\n",
    "    db_path=db_path,\n",
    "    max_samples=15,\n",
    "    save_schema_to=schema_path\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ Schema exploration complete!\")\n",
    "\n",
    "# Display schema results\n",
    "print(f\"\\nüìã Discovered Schema:\")\n",
    "print(f\"  Summary: {schema['summary']}\")\n",
    "print(f\"  Node Types: {list(schema['nodes'].keys())}\")\n",
    "print(f\"  Edge Types: {list(schema['edges'].keys())}\")\n",
    "\n",
    "# Show detailed info for one node type\n",
    "if 'Employee' in schema['nodes']:\n",
    "    emp_info = schema['nodes']['Employee']\n",
    "    print(f\"\\nüë§ Employee Node Details:\")\n",
    "    print(f\"  Description: {emp_info['description']}\")\n",
    "    print(f\"  Properties: {emp_info['properties']}\")\n",
    "    print(f\"  Example: {emp_info['example_values']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Data Generator Module\n",
    "\n",
    "The `DataGenerator` creates training datasets from graph schemas. It can work with any schema JSON file, regardless of how it was created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß DataGenerator Info:\n",
      "  name: DataGenerator\n",
      "  version: 1.0.0\n",
      "  description: Generate training data from graph schemas\n",
      "  inputs: {'from_schema': ['schema_path', 'num_examples', 'output_path', 'complexity_distribution', 'db_path'], 'from_dict': ['schema', 'num_examples', 'output_path', 'complexity_distribution', 'kuzu_adapter']}\n",
      "  outputs: ['dataset', 'statistics']\n",
      "\n",
      "üìù Generating training data...\n",
      "DEBUG: Generating 30 examples for complexity 1\n",
      "DEBUG: Generating batch of 20, remaining=30, attempts=0\n",
      "DEBUG: LLM prompt will use node_types: ['company_Employee', 'company_Department', 'company_Project']\n",
      "DEBUG: LLM prompt will use edge_types: ['company_WORKED_ON_Employee_to_Project', 'company_BELONGS_TO_Employee_to_Department', 'company_OWNED_BY_Project_to_Department']\n",
      "DEBUG: LLM prompt (first 500 chars): Graph Schema:\n",
      "{\n",
      "  \"nodes\": {\n",
      "    \"company_Employee\": {\n",
      "      \"properties\": [\n",
      "        \"id\",\n",
      "        \"salary\",\n",
      "        \"name\",\n",
      "        \"department\",\n",
      "        \"level\"\n",
      "      ],\n",
      "      \"description\": \"This node represents an employee in a company. It contains information about the employee's ID, salary, name, department, and level.\",\n",
      "      \"example_values\": {\n",
      "        \"id\": \"emp1\",\n",
      "        \"salary\": 120000.0,\n",
      "        \"name\": \"Alice Johnson\",\n",
      "        \"department\": \"Engineering\",\n",
      "        \"level\": \"Senior\"...\n",
      "DEBUG: Valid query: MATCH (n:company_Employee) WHERE n.id = 'emp1' RETURN n...\n",
      "DEBUG: Valid query: MATCH (n:company_Employee) RETURN n...\n",
      "DEBUG: Valid query: MATCH (n:company_Employee) WHERE n.id = 'emp4' RETURN n.name...\n",
      "DEBUG: Valid query: MATCH (n:company_Employee) RETURN count(n)...\n",
      "DEBUG: Valid query: MATCH (e:company_Employee)-[:company_BELONGS_TO_Employee_to_Department]->(d:company_Department) WHER...\n",
      "DEBUG: Valid query: MATCH (n:company_Employee) WHERE n.name = 'Alice Johnson' RETURN n.salary...\n",
      "DEBUG: Valid query: MATCH (n:company_Department) WHERE n.name = 'Engineering' RETURN n.head_count...\n",
      "DEBUG: Valid query: MATCH (n:company_Project) WHERE n.name = 'Alpha' RETURN n.status...\n",
      "DEBUG: Valid query: MATCH (n:company_Project) RETURN n...\n",
      "DEBUG: Valid query: MATCH (e:company_Employee)-[:company_BELONGS_TO_Employee_to_Department]->(d:company_Department) WHER...\n",
      "DEBUG: Valid query: MATCH (n:company_Department) WHERE n.name = 'Marketing' RETURN n.budget...\n",
      "DEBUG: Valid query: MATCH (n:company_Department) WHERE n.id = 'dept3' RETURN n...\n",
      "DEBUG: Valid query: MATCH (n:company_Employee) WHERE n.name = 'Bob Smith' RETURN n.level...\n",
      "DEBUG: Valid query: MATCH (n:company_Project) WHERE n.id = 'proj2' RETURN n...\n",
      "DEBUG: Valid query: MATCH (n:company_Department) RETURN count(n)...\n",
      "DEBUG: Valid query: MATCH (n:company_Employee) WHERE n.level = 'Senior' RETURN n.name...\n",
      "DEBUG: Valid query: MATCH (e:company_Employee)-[:company_WORKED_ON_Employee_to_Project]->(p:company_Project) WHERE p.nam...\n",
      "DEBUG: Valid query: MATCH (n:company_Project) WHERE n.name = 'Beta' RETURN n.budget...\n",
      "DEBUG: Valid query: MATCH (e:company_Employee)-[:company_BELONGS_TO_Employee_to_Department]->(d:company_Department) WHER...\n",
      "DEBUG: Valid query: MATCH (p:company_Project)-[:company_OWNED_BY_Project_to_Department]->(d:company_Department) WHERE p....\n",
      "DEBUG: Generated batch with 20 examples\n",
      "DEBUG: 20 examples passed validation\n",
      "DEBUG: Generating batch of 10, remaining=10, attempts=20\n",
      "DEBUG: LLM prompt will use node_types: ['company_Employee', 'company_Department', 'company_Project']\n",
      "DEBUG: LLM prompt will use edge_types: ['company_WORKED_ON_Employee_to_Project', 'company_BELONGS_TO_Employee_to_Department', 'company_OWNED_BY_Project_to_Department']\n",
      "DEBUG: LLM prompt (first 500 chars): Graph Schema:\n",
      "{\n",
      "  \"nodes\": {\n",
      "    \"company_Employee\": {\n",
      "      \"properties\": [\n",
      "        \"id\",\n",
      "        \"salary\",\n",
      "        \"name\",\n",
      "        \"department\",\n",
      "        \"level\"\n",
      "      ],\n",
      "      \"description\": \"This node represents an employee in a company. It contains information about the employee's ID, salary, name, department, and level.\",\n",
      "      \"example_values\": {\n",
      "        \"id\": \"emp1\",\n",
      "        \"salary\": 120000.0,\n",
      "        \"name\": \"Alice Johnson\",\n",
      "        \"department\": \"Engineering\",\n",
      "        \"level\": \"Senior\"...\n",
      "DEBUG: Valid query: MATCH (e:company_Employee) RETURN e...\n",
      "DEBUG: Valid query: MATCH (e:company_Employee {id: 'emp1'}) RETURN e.name...\n",
      "DEBUG: Valid query: MATCH (d:company_Department {name: 'Engineering'}) RETURN d.budget...\n",
      "DEBUG: Valid query: MATCH (p:company_Project {name: 'Alpha'}) RETURN p.status...\n",
      "DEBUG: Valid query: MATCH (e:company_Employee {name: 'Alice Johnson'}) RETURN e.salary...\n",
      "DEBUG: Valid query: MATCH (d:company_Department {name: 'Marketing'}) RETURN d.head_count...\n",
      "DEBUG: Valid query: MATCH (p:company_Project {name: 'Beta'}) RETURN p...\n",
      "DEBUG: Valid query: MATCH (d:company_Department) RETURN d...\n",
      "DEBUG: Valid query: MATCH (e:company_Employee {level: 'Junior', department: 'Engineering'}) RETURN e.name...\n",
      "DEBUG: Valid query: MATCH (p:company_Project {status: 'Active'}) RETURN p...\n",
      "DEBUG: Generated batch with 10 examples\n",
      "DEBUG: 10 examples passed validation\n",
      "DEBUG: Generating 30 examples for complexity 2\n",
      "DEBUG: Generating batch of 20, remaining=30, attempts=0\n",
      "DEBUG: LLM prompt will use node_types: ['company_Employee', 'company_Department', 'company_Project']\n",
      "DEBUG: LLM prompt will use edge_types: ['company_WORKED_ON_Employee_to_Project', 'company_BELONGS_TO_Employee_to_Department', 'company_OWNED_BY_Project_to_Department']\n",
      "DEBUG: LLM prompt (first 500 chars): Graph Schema:\n",
      "{\n",
      "  \"nodes\": {\n",
      "    \"company_Employee\": {\n",
      "      \"properties\": [\n",
      "        \"id\",\n",
      "        \"salary\",\n",
      "        \"name\",\n",
      "        \"department\",\n",
      "        \"level\"\n",
      "      ],\n",
      "      \"description\": \"This node represents an employee in a company. It contains information about the employee's ID, salary, name, department, and level.\",\n",
      "      \"example_values\": {\n",
      "        \"id\": \"emp1\",\n",
      "        \"salary\": 120000.0,\n",
      "        \"name\": \"Alice Johnson\",\n",
      "        \"department\": \"Engineering\",\n",
      "        \"level\": \"Senior\"...\n",
      "DEBUG: Valid query: MATCH (e:company_Employee) WHERE e.salary > 100000 and e.department = 'Engineering' RETURN e.name...\n",
      "DEBUG: Valid query: MATCH (e:company_Employee) WHERE e.department = 'Sales' RETURN e...\n",
      "DEBUG: Valid query: MATCH (d:company_Department) WHERE d.head_count > 15 RETURN sum(d.budget)...\n",
      "DEBUG: Valid query: MATCH (e:company_Employee) WHERE e.department = 'Engineering' and e.salary < 100000 RETURN e.name...\n",
      "DEBUG: Valid query: MATCH (p:company_Project) WHERE p.status = 'Active' RETURN p...\n",
      "DEBUG: Valid query: MATCH (p:company_Project) WHERE p.status = 'Planning' RETURN sum(p.budget)...\n",
      "DEBUG: Valid query: MATCH (e:company_Employee)-[r:company_BELONGS_TO_Employee_to_Department]->(d:company_Department) WHE...\n",
      "DEBUG: Valid query: MATCH (e:company_Employee) WHERE e.department = 'Marketing' and e.salary > 80000 RETURN count(e)...\n",
      "DEBUG: Valid query: MATCH (e:company_Employee)-[:company_WORKED_ON_Employee_to_Project]->(p:company_Project) WHERE p.nam...\n",
      "DEBUG: Valid query: MATCH (e:company_Employee)-[r:company_WORKED_ON_Employee_to_Project]->(p:company_Project) WHERE e.na...\n",
      "DEBUG: Valid query: MATCH (d:company_Department) WHERE d.budget > 1000000 RETURN d.name...\n",
      "DEBUG: Valid query: MATCH (e:company_Employee) WHERE e.department = 'Engineering' and e.level = 'Senior' RETURN e.name...\n",
      "DEBUG: Valid query: MATCH (e:company_Employee)-[r:company_WORKED_ON_Employee_to_Project]->(p:company_Project) WHERE r.ho...\n",
      "DEBUG: Valid query: MATCH (e:company_Employee) WHERE e.department = 'Engineering' and e.level = 'Junior' RETURN e.name...\n",
      "DEBUG: Valid query: MATCH (e:company_Employee) WHERE e.department = 'Engineering' RETURN sum(e.salary)...\n",
      "DEBUG: Valid query: MATCH (e:company_Employee)-[r:company_WORKED_ON_Employee_to_Project]->(p:company_Project) WHERE r.ro...\n",
      "DEBUG: Valid query: MATCH (e:company_Employee) WHERE e.level = 'Mid' and e.salary < 90000 RETURN e.name...\n",
      "DEBUG: Valid query: MATCH (p:company_Project) WHERE p.budget < 500000 RETURN p.name...\n",
      "DEBUG: Valid query: MATCH (d:company_Department) WHERE d.head_count < 15 RETURN d.name...\n",
      "DEBUG: Valid query: MATCH (e:company_Employee)-[r:company_WORKED_ON_Employee_to_Project]->(p:company_Project) WHERE r.ho...\n",
      "DEBUG: Generated batch with 20 examples\n",
      "DEBUG: 20 examples passed validation\n",
      "DEBUG: Generating batch of 10, remaining=10, attempts=20\n",
      "DEBUG: LLM prompt will use node_types: ['company_Employee', 'company_Department', 'company_Project']\n",
      "DEBUG: LLM prompt will use edge_types: ['company_WORKED_ON_Employee_to_Project', 'company_BELONGS_TO_Employee_to_Department', 'company_OWNED_BY_Project_to_Department']\n",
      "DEBUG: LLM prompt (first 500 chars): Graph Schema:\n",
      "{\n",
      "  \"nodes\": {\n",
      "    \"company_Employee\": {\n",
      "      \"properties\": [\n",
      "        \"id\",\n",
      "        \"salary\",\n",
      "        \"name\",\n",
      "        \"department\",\n",
      "        \"level\"\n",
      "      ],\n",
      "      \"description\": \"This node represents an employee in a company. It contains information about the employee's ID, salary, name, department, and level.\",\n",
      "      \"example_values\": {\n",
      "        \"id\": \"emp1\",\n",
      "        \"salary\": 120000.0,\n",
      "        \"name\": \"Alice Johnson\",\n",
      "        \"department\": \"Engineering\",\n",
      "        \"level\": \"Senior\"...\n",
      "DEBUG: Valid query: MATCH (e:company_Employee) WHERE e.salary > 100000 AND e.department = 'Engineering' RETURN e.name...\n",
      "DEBUG: Valid query: MATCH (p:company_Project)-[:company_OWNED_BY_Project_to_Department]->(d:company_Department) WHERE p....\n",
      "DEBUG: Valid query: MATCH (e:company_Employee) WHERE e.level = 'Senior' AND NOT e.department = 'Sales' RETURN e.name...\n",
      "DEBUG: Valid query: MATCH (p:company_Project) WHERE p.budget > 400000 RETURN p...\n",
      "DEBUG: Valid query: MATCH (e:company_Employee)-[r:company_BELONGS_TO_Employee_to_Department]->(d:company_Department) WHE...\n",
      "DEBUG: Valid query: MATCH (e:company_Employee)-[:company_WORKED_ON_Employee_to_Project]->(p:company_Project) WHERE p.nam...\n",
      "DEBUG: Valid query: MATCH (e:company_Employee) WHERE e.salary < 90000 AND NOT e.department = 'Marketing' RETURN e.name...\n",
      "DEBUG: Valid query: MATCH (e:company_Employee)-[:company_BELONGS_TO_Employee_to_Department]->(d:company_Department) WHER...\n",
      "DEBUG: Valid query: MATCH (p:company_Project)-[:company_OWNED_BY_Project_to_Department]->(d:company_Department) WHERE NO...\n",
      "DEBUG: Valid query: MATCH (e:company_Employee) WHERE e.level = 'Mid' AND e.salary > 80000 RETURN e.name...\n",
      "DEBUG: Generated batch with 10 examples\n",
      "DEBUG: 10 examples passed validation\n",
      "DEBUG: Generating 20 examples for complexity 3\n",
      "DEBUG: Generating batch of 20, remaining=20, attempts=0\n",
      "DEBUG: LLM prompt will use node_types: ['company_Employee', 'company_Department', 'company_Project']\n",
      "DEBUG: LLM prompt will use edge_types: ['company_WORKED_ON_Employee_to_Project', 'company_BELONGS_TO_Employee_to_Department', 'company_OWNED_BY_Project_to_Department']\n",
      "DEBUG: LLM prompt (first 500 chars): Graph Schema:\n",
      "{\n",
      "  \"nodes\": {\n",
      "    \"company_Employee\": {\n",
      "      \"properties\": [\n",
      "        \"id\",\n",
      "        \"salary\",\n",
      "        \"name\",\n",
      "        \"department\",\n",
      "        \"level\"\n",
      "      ],\n",
      "      \"description\": \"This node represents an employee in a company. It contains information about the employee's ID, salary, name, department, and level.\",\n",
      "      \"example_values\": {\n",
      "        \"id\": \"emp1\",\n",
      "        \"salary\": 120000.0,\n",
      "        \"name\": \"Alice Johnson\",\n",
      "        \"department\": \"Engineering\",\n",
      "        \"level\": \"Senior\"...\n",
      "DEBUG: Valid query: MATCH (e:company_Employee)-[:company_BELONGS_TO_Employee_to_Department]->(d:company_Department {name...\n",
      "DEBUG: Valid query: MATCH (e:company_Employee {name:'Alice Johnson'})-[:company_WORKED_ON_Employee_to_Project]->(p:compa...\n",
      "DEBUG: Valid query: MATCH (p:company_Project {name:'Alpha'})-[:company_OWNED_BY_Project_to_Department]->(d:company_Depar...\n",
      "DEBUG: Valid query: MATCH (e:company_Employee {name:'Bob Smith'}) RETURN e.salary...\n",
      "DEBUG: Valid query: MATCH (d:company_Department {name:'Marketing'}) RETURN d.budget...\n",
      "DEBUG: Valid query: MATCH (e:company_Employee {name:'Carol White'})-[r:company_WORKED_ON_Employee_to_Project]->(p:compan...\n",
      "DEBUG: Valid query: MATCH (e:company_Employee {level:'Senior'}) RETURN e.name...\n",
      "DEBUG: Valid query: MATCH (p:company_Project {name:'Beta'})-[:company_OWNED_BY_Project_to_Department]->(d:company_Depart...\n",
      "DEBUG: Valid query: MATCH (p:company_Project {name:'Alpha'}) RETURN p.budget...\n",
      "DEBUG: Valid query: MATCH (e:company_Employee)-[r:company_WORKED_ON_Employee_to_Project]->(p:company_Project) WHERE r.ho...\n",
      "DEBUG: Valid query: MATCH (e:company_Employee {level:'Junior'})-[:company_BELONGS_TO_Employee_to_Department]->(d:company...\n",
      "DEBUG: Valid query: MATCH (e:company_Employee)-[r:company_WORKED_ON_Employee_to_Project {role:'Lead'}]->(p:company_Proje...\n",
      "DEBUG: Valid query: MATCH (d:company_Department {name:'Sales'}) RETURN d.head_count...\n",
      "DEBUG: Valid query: MATCH (p:company_Project {status:'Active'}) RETURN p.name...\n",
      "DEBUG: Valid query: MATCH (e:company_Employee {name:'Alice Johnson'})-[r:company_WORKED_ON_Employee_to_Project]->(p:comp...\n",
      "DEBUG: Valid query: MATCH (e:company_Employee)-[:company_WORKED_ON_Employee_to_Project]->(p:company_Project {name:'Beta'...\n",
      "DEBUG: Valid query: MATCH (e:company_Employee)-[r:company_WORKED_ON_Employee_to_Project]->(p:company_Project {name:'Alph...\n",
      "DEBUG: Valid query: MATCH (e:company_Employee)-[r:company_WORKED_ON_Employee_to_Project {role:'Developer'}]->(p:company_...\n",
      "DEBUG: Valid query: MATCH (p:company_Project {name:'Beta'})-[:company_OWNED_BY_Project_to_Department]->(d:company_Depart...\n",
      "DEBUG: Valid query: MATCH (e:company_Employee)-[:company_BELONGS_TO_Employee_to_Department]->(d:company_Department {name...\n",
      "DEBUG: Generated batch with 20 examples\n",
      "DEBUG: 20 examples passed validation\n",
      "DEBUG: Generating 20 examples for complexity 4\n",
      "DEBUG: Generating batch of 20, remaining=20, attempts=0\n",
      "DEBUG: LLM prompt will use node_types: ['company_Employee', 'company_Department', 'company_Project']\n",
      "DEBUG: LLM prompt will use edge_types: ['company_WORKED_ON_Employee_to_Project', 'company_BELONGS_TO_Employee_to_Department', 'company_OWNED_BY_Project_to_Department']\n",
      "DEBUG: LLM prompt (first 500 chars): Graph Schema:\n",
      "{\n",
      "  \"nodes\": {\n",
      "    \"company_Employee\": {\n",
      "      \"properties\": [\n",
      "        \"id\",\n",
      "        \"salary\",\n",
      "        \"name\",\n",
      "        \"department\",\n",
      "        \"level\"\n",
      "      ],\n",
      "      \"description\": \"This node represents an employee in a company. It contains information about the employee's ID, salary, name, department, and level.\",\n",
      "      \"example_values\": {\n",
      "        \"id\": \"emp1\",\n",
      "        \"salary\": 120000.0,\n",
      "        \"name\": \"Alice Johnson\",\n",
      "        \"department\": \"Engineering\",\n",
      "        \"level\": \"Senior\"...\n",
      "DEBUG: Valid query: MATCH (e:company_Employee) RETURN e.name ORDER BY e.salary DESC LIMIT 1...\n",
      "DEBUG: Valid query: MATCH (e:company_Employee)-[:company_BELONGS_TO_Employee_to_Department]->(d:company_Department) RETU...\n",
      "DEBUG: Valid query: MATCH (p:company_Project) RETURN SUM(p.budget) as TotalBudget...\n",
      "DEBUG: Valid query: MATCH (e:company_Employee)-[:company_BELONGS_TO_Employee_to_Department]->(d:company_Department {name...\n",
      "DEBUG: Valid query: MATCH (e:company_Employee)-[r:company_WORKED_ON_Employee_to_Project]->(p:company_Project {name: 'Alp...\n",
      "DEBUG: Valid query: MATCH (p:company_Project)-[:company_OWNED_BY_Project_to_Department]->(d:company_Department) RETURN d...\n",
      "DEBUG: Valid query: MATCH (p:company_Project) RETURN MAX(p.budget) as MaxBudget...\n",
      "DEBUG: Valid query: MATCH (e:company_Employee)-[:company_BELONGS_TO_Employee_to_Department]->(d:company_Department {name...\n",
      "DEBUG: Valid query: MATCH (e:company_Employee {level: 'Senior'}) RETURN MIN(e.salary) as MinSalary...\n",
      "DEBUG: Valid query: MATCH (e:company_Employee)-[:company_WORKED_ON_Employee_to_Project]->(p:company_Project) RETURN p.na...\n",
      "DEBUG: Valid query: MATCH (d:company_Department) RETURN SUM(d.budget) as TotalDepartmentBudget...\n",
      "DEBUG: Valid query: MATCH (e:company_Employee)-[r:company_BELONGS_TO_Employee_to_Department]->(d:company_Department {nam...\n",
      "DEBUG: Valid query: MATCH (p:company_Project)-[:company_OWNED_BY_Project_to_Department]->(d:company_Department {name: 'E...\n",
      "DEBUG: Valid query: MATCH (e:company_Employee)-[r:company_WORKED_ON_Employee_to_Project]->(p:company_Project) RETURN MAX...\n",
      "DEBUG: Valid query: MATCH (d:company_Department) RETURN COUNT(d) as DepartmentCount...\n",
      "DEBUG: Valid query: MATCH (e:company_Employee)-[:company_BELONGS_TO_Employee_to_Department]->(d:company_Department {name...\n",
      "DEBUG: Valid query: MATCH (e:company_Employee)-[r:company_WORKED_ON_Employee_to_Project {role: 'Lead'}]->(p:company_Proj...\n",
      "DEBUG: Valid query: MATCH (e:company_Employee {level: 'Junior'}) RETURN AVG(e.salary) as AverageSalary...\n",
      "DEBUG: Valid query: MATCH (p:company_Project)-[:company_OWNED_BY_Project_to_Department]->(d:company_Department {name: 'S...\n",
      "DEBUG: Valid query: MATCH (e:company_Employee) RETURN e.level, COUNT(e) AS EmployeeCount...\n",
      "DEBUG: Generated batch with 20 examples\n",
      "DEBUG: 20 examples passed validation\n",
      "\n",
      "‚úÖ Training data generated!\n",
      "\n",
      "üìä Dataset Statistics:\n",
      "  Total examples: 100\n",
      "  Complexity distribution: {1: 30, 2: 30, 3: 20, 4: 20}\n",
      "  Intent distribution: {'Retrieve specific node by id': 3, 'Retrieve all nodes of a type': 2, 'Retrieve specific property from node': 7, 'Count all nodes of a type': 2, 'Retrieve related node': 2, 'Retrieve related nodes': 3, 'Retrieve specific nodes with property': 1, 'Exploratory': 10, 'Specific': 10, 'Find specific employees based on salary and department': 2, 'Retrieve all employees belonging to a specific department': 1, 'Calculate the total budget of departments based on head count': 1, 'Retrieve all active projects': 1, 'Calculate the total budget of projects in a specific phase': 1, 'Find employees based on when they joined their department': 1, 'Count the employees of a specific department with a certain salary': 1, 'Find employees working on a specific project': 1, \"Find specific employee's working hours on a specific project\": 1, 'Find departments based on budget': 1, 'Find employees of a specific level in a specific department': 2, 'Find employees based on working hours on a specific project': 1, 'Calculate total salary of a specific department': 1, \"Find employee's role in a specific project\": 1, 'Find employees based on level and salary': 1, 'Find projects based on budget': 1, 'Find departments based on head count': 1, 'Count employees based on working hours on any project': 1, 'User is trying to identify high earning employees within the Engineering department': 1, 'User wants to find out which department is responsible for a specific project': 1, 'User wants to filter employees based on their level and department': 1, 'User is looking for projects with budget exceeding a certain amount': 1, 'User wants to know the employees who joined a particular department after a specific date': 1, 'User is trying to find out the employees who have worked on a specific project': 1, 'User is interested in employees from non-marketing departments with salary below a certain amount': 1, 'User wants to identify employees from a high-budget department': 1, 'User is trying to find out projects from departments other than Engineering': 1, 'User is interested in mid-level employees with salary above a certain amount': 1, 'Detailed': 6, 'Analytical': 4, 'Find the highest paid employee': 1, 'Get the count of employees in each department': 1, 'Calculate the total budget of all projects': 1, 'Calculate the average salary in a specific department': 1, 'Find the employee with most hours worked on a specific project': 1, 'Count the number of projects in each department': 1, 'Find the maximum budget of a project': 1, 'List the employees in a specific department': 1, 'Find the minimum salary of employees in a particular level': 1, 'Find the project with the most employees': 1, 'Calculate the total budget of all departments': 1, 'Find the most recent employee to join a specific department': 1, 'Calculate the average budget of projects in a specific department': 1, 'Find the maximum hours worked by an employee on a project': 1, 'Count the number of departments in the company': 1, 'Calculate the total salary of employees in a specific department': 1, 'Find the employees with a specific role in a particular project': 1, 'Calculate the average salary of employees in a particular level': 1, 'Find the minimum budget of projects in a specific department': 1, 'Get the count of employees in each level': 1}\n",
      "\n",
      "üí° Sample Training Examples:\n",
      "\n",
      "  Example 1:\n",
      "    Question: Who is the employee with the ID 'emp1'?\n",
      "    Cypher: MATCH (n:company_Employee) WHERE n.id = 'emp1' RETURN n...\n",
      "    Complexity: 1\n",
      "    Intent: Retrieve specific node by id\n",
      "\n",
      "  Example 2:\n",
      "    Question: Can you show me all the employees in the company?\n",
      "    Cypher: MATCH (n:company_Employee) RETURN n...\n",
      "    Complexity: 1\n",
      "    Intent: Retrieve all nodes of a type\n",
      "\n",
      "  Example 3:\n",
      "    Question: What's the name of the 'emp4'?\n",
      "    Cypher: MATCH (n:company_Employee) WHERE n.id = 'emp4' RETURN n.name...\n",
      "    Complexity: 1\n",
      "    Intent: Retrieve specific property from node\n"
     ]
    }
   ],
   "source": [
    "# Initialize DataGenerator\n",
    "generator = DataGenerator(llm_provider=\"openai\", llm_model=\"gpt-4\")\n",
    "schema_path = work_dir / \"company_schema.json\"# Show module info\n",
    "db_path = work_dir / \"company_db\"\n",
    "\n",
    "\n",
    "print(\"üîß DataGenerator Info:\")\n",
    "info = generator.get_info()\n",
    "for key, value in info.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "print(\"\\nüìù Generating training data...\")\n",
    "\n",
    "# Generate dataset from the schema we created\n",
    "dataset_path = work_dir / \"company_dataset.jsonl\"\n",
    "dataset = generator.generate_from_schema(\n",
    "    schema_path=schema_path,\n",
    "    num_examples=100,  # Small number for demo\n",
    "    output_path=dataset_path,\n",
    "    complexity_distribution={\n",
    "        1: 0.3,  # Simple lookups\n",
    "        2: 0.3,  # Filtered queries  \n",
    "        3: 0.2,  # Relationships\n",
    "        4: 0.2,  # Aggregations\n",
    "    },\n",
    "    db_path=db_path  # For validation\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ Training data generated!\")\n",
    "\n",
    "# Show dataset statistics\n",
    "print(f\"\\nüìä Dataset Statistics:\")\n",
    "print(f\"  Total examples: {len(dataset)}\")\n",
    "\n",
    "# Analyze complexity distribution\n",
    "complexity_counts = {}\n",
    "intent_counts = {}\n",
    "for item in dataset:\n",
    "    complexity = item.get('complexity', 0)\n",
    "    intent = item.get('intent', 'unknown')\n",
    "    complexity_counts[complexity] = complexity_counts.get(complexity, 0) + 1\n",
    "    intent_counts[intent] = intent_counts.get(intent, 0) + 1\n",
    "\n",
    "print(f\"  Complexity distribution: {complexity_counts}\")\n",
    "print(f\"  Intent distribution: {intent_counts}\")\n",
    "\n",
    "# Show sample examples\n",
    "print(f\"\\nüí° Sample Training Examples:\")\n",
    "for i, example in enumerate(dataset[:3], 1):\n",
    "    print(f\"\\n  Example {i}:\")\n",
    "    print(f\"    Question: {example.get('question', 'N/A')}\")\n",
    "    print(f\"    Cypher: {example.get('cypher', 'N/A')[:80]}...\")\n",
    "    print(f\"    Complexity: {example.get('complexity', 'N/A')}\")\n",
    "    print(f\"    Intent: {example.get('intent', 'N/A')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Model Trainer Module\n",
    "\n",
    "The `ModelTrainer` fine-tunes language models on training datasets. It can work with any dataset file, regardless of how it was created.\n",
    "\n",
    "**Note**: Model training is computationally expensive and time-consuming. In this demo, we'll show the setup but skip the actual training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß ModelTrainer Info:\n",
      "  name: ModelTrainer\n",
      "  version: 1.0.0\n",
      "  description: Fine-tune models on graph query datasets\n",
      "  inputs: {'from_file': ['dataset_path', 'model_name', 'output_dir', 'epochs', 'learning_rate', 'batch_size', 'lora_rank'], 'from_data': ['dataset', 'model_name', 'output_dir', 'epochs', 'learning_rate', 'batch_size', 'lora_rank']}\n",
      "  outputs: ['model', 'training_stats', 'model_path']\n",
      "\n",
      "‚öôÔ∏è Training Configuration:\n",
      "  dataset_path: modular_demo_workspace/company_dataset.jsonl\n",
      "  base_model: meta-llama/Llama-3.2-1B-Instruct\n",
      "  epochs: 5\n",
      "  learning_rate: 0.0005\n",
      "  batch_size: 1\n",
      "  lora_rank: 8\n",
      "  output_dir: modular_demo_workspace/company_model\n",
      "\n",
      "üéØ Model Training:\n",
      "trainable params: 5,636,096 || all params: 1,241,450,496 || trainable%: 0.4540\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be0e095937ba45ebbd0cb06578743243",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/90 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d880d6d004a6421e86f8986d2d0be3af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminfriedman/repos/auto-graph-rag/.venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "source": [
    "# Initialize ModelTrainer\n",
    "trainer = ModelTrainer()\n",
    "\n",
    "\n",
    "# Show module info\n",
    "print(\"üîß ModelTrainer Info:\")\n",
    "info = trainer.get_info()\n",
    "for key, value in info.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# Show training configuration\n",
    "print(\"\\n‚öôÔ∏è Training Configuration:\")\n",
    "dataset_path = work_dir / \"company_dataset.jsonl\"\n",
    "training_config = {\n",
    "    \"dataset_path\":dataset_path,\n",
    "    \"base_model\": \"meta-llama/Llama-3.2-1B-Instruct\",\n",
    "    \"epochs\": 5,\n",
    "    \"learning_rate\": 5e-4,\n",
    "    \"batch_size\": 1,\n",
    "    \"lora_rank\": 8,\n",
    "    \"output_dir\": str(work_dir / \"company_model\")\n",
    "}\n",
    "\n",
    "for key, value in training_config.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "print(\"\\nüéØ Model Training:\")\n",
    "\n",
    "model = trainer.train_from_file(\n",
    "    dataset_path=Path(training_config['dataset_path']),\n",
    "    model_name=training_config['base_model'],\n",
    "    output_dir=Path(training_config['output_dir']),\n",
    "    epochs=training_config['epochs'],\n",
    "    learning_rate=training_config['learning_rate'],\n",
    "    batch_size=training_config['batch_size'],\n",
    "    lora_rank=training_config['lora_rank']\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Query Executor Module\n",
    "\n",
    "The `QueryExecutor` executes natural language queries using fine-tuned models and graph databases. It can work with any trained model and database combination.\n",
    "\n",
    "**This step uses the actual trained model from Step 4 and the database from Step 1, demonstrating how assets can be reused across modules.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not detect model name, using default\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß QueryExecutor Info:\n",
      "  name: QueryExecutor\n",
      "  version: 1.0.0\n",
      "  description: Execute queries with fine-tuned models\n",
      "  inputs: {'with_paths': ['question', 'model_path', 'db_path', 'return_cypher', 'format_results'], 'with_instances': ['question', 'model', 'kuzu_adapter', 'return_cypher', 'format_results']}\n",
      "  outputs: ['success', 'cypher', 'results', 'count', 'error']\n",
      "\n",
      "üéØ Using Assets from Previous Steps:\n",
      "  Model: modular_demo_workspace/company_model (from Step 4)\n",
      "  Database: modular_demo_workspace/company_db (from Step 1)\n",
      "\n",
      "‚ùì Test Questions:\n",
      "  1. Who are all the employees?\n",
      "  2. Which employees work in Engineering?\n",
      "  3. What projects has Alice Johnson worked on?\n",
      "  4. What is the average salary by department?\n",
      "  5. Which departments have the highest budgets?\n",
      "\n",
      "ü§ñ Query Execution with Trained Model:\n",
      "\n",
      "  Query 1: Who are all the employees?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "/Users/benjaminfriedman/repos/auto-graph-rag/.venv/lib/python3.11/site-packages/bitsandbytes/cextension.py:34: UserWarning: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "  warn(\"The installed version of bitsandbytes was compiled without GPU support. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'cadam32bit_grad_fp32'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Query failed (attempt 1): Binder exception: Table company_OWNED_BY_Employee_to_Employee does not exist.\n",
      "Query failed (attempt 2): Binder exception: Table company_OWNED_BY_Employee_to_Employee does not exist.\n",
      "Could not detect model name, using default\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ‚ùå Error: Binder exception: Table company_OWNED_BY_Employee_to_Employee does not exist.\n",
      "\n",
      "  Query 2: Which employees work in Engineering?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Query failed (attempt 1): Binder exception: Cannot find property role for e.\n",
      "Query failed (attempt 2): Binder exception: Function LIST_EXTRACT did not receive correct arguments:\n",
      "Actual:   (NODE,STRING)\n",
      "Expected: (LIST,INT64) -> ANY\n",
      "          (STRING,INT64) -> STRING\n",
      "          (ARRAY,INT64) -> ANY\n",
      "\n",
      "\n",
      "Could not detect model name, using default\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ‚ùå Error: Binder exception: Function LIST_EXTRACT did not receive correct arguments:\n",
      "Actual:   (NODE,STRING)\n",
      "Expected: (LIST,INT64) -> ANY\n",
      "          (STRING,INT64) -> STRING\n",
      "          (ARRAY,INT64) -> ANY\n",
      "\n",
      "\n",
      "\n",
      "  Query 3: What projects has Alice Johnson worked on?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not detect model name, using default\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ‚úÖ Generated Cypher: MATCH (e:company_Employee {name: 'Alice Johnson'})<-[:company_WORKED_ON_Employee_to_Project]-(p:company_Project) RETURN p.name\n",
      "    üìä Results: 0 rows\n",
      "\n",
      "  Query 4: What is the average salary by department?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Query failed (attempt 1): Parser exception: Invalid input < BY>: expected rule ku_Statements (line: 1, offset: 136)\n",
      "\"MATCH (e:company_Employee)-[r:company_BELONGS_TO_Employee_to_Department]->(d:company_Department) RETURN AVG(r.salary) AS Average_Salary BY d.name ORDER BY Average_Salary DESC\"\n",
      "                                                                                                                                         ^^\n",
      "Query failed (attempt 2): Parser exception: Invalid input < BY>: expected rule ku_Statements (line: 1, offset: 136)\n",
      "\"MATCH (e:company_Employee)-[r:company_BELONGS_TO_Employee_to_Department]->(d:company_Department) RETURN AVG(r.salary) AS Average_Salary BY d.name ORDER BY Average_Salary DESC\"\n",
      "                                                                                                                                         ^^\n",
      "Could not detect model name, using default\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ‚ùå Error: Parser exception: Invalid input < BY>: expected rule ku_Statements (line: 1, offset: 136)\n",
      "\"MATCH (e:company_Employee)-[r:company_BELONGS_TO_Employee_to_Department]->(d:company_Department) RETURN AVG(r.salary) AS Average_Salary BY d.name ORDER BY Average_Salary DESC\"\n",
      "                                                                                                                                         ^^\n",
      "\n",
      "  Query 5: Which departments have the highest budgets?\n",
      "    ‚úÖ Generated Cypher: MATCH (d:company_Department)-[:company_BELONGS_TO_Employee_to_Department]->(e:company_Department) RETURN e.name AS Department, d.budget AS Budget ORDER BY Budget DESC LIMIT 10\n",
      "    üìä Results: 0 rows\n"
     ]
    }
   ],
   "source": [
    "# Initialize QueryExecutor\n",
    "executor = QueryExecutor()\n",
    "\n",
    "# Use the trained model from Step 4 and database from Step 1\n",
    "model_path = work_dir / \"company_model\"  # From Step 4 ModelTrainer\n",
    "db_path = work_dir / \"company_db\"        # From Step 1 GraphBuilder\n",
    "\n",
    "print(\"üîß QueryExecutor Info:\")\n",
    "info = executor.get_info()\n",
    "for key, value in info.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "print(f\"\\nüéØ Using Assets from Previous Steps:\")\n",
    "print(f\"  Model: {model_path} (from Step 4)\")\n",
    "print(f\"  Database: {db_path} (from Step 1)\")\n",
    "\n",
    "# Test questions we'd like to ask\n",
    "test_questions = [\n",
    "    \"Who are all the employees?\",\n",
    "    \"Which employees work in Engineering?\", \n",
    "    \"What projects has Alice Johnson worked on?\",\n",
    "    \"What is the average salary by department?\",\n",
    "    \"Which departments have the highest budgets?\"\n",
    "]\n",
    "\n",
    "print(\"\\n‚ùì Test Questions:\")\n",
    "for i, question in enumerate(test_questions, 1):\n",
    "    print(f\"  {i}. {question}\")\n",
    "\n",
    "print(\"\\nü§ñ Query Execution with Trained Model:\")   \n",
    "for i, question in enumerate(test_questions, 1):\n",
    "    print(f\"\\n  Query {i}: {question}\")\n",
    "    \n",
    "    result = executor.query_with_model(\n",
    "        question=question,\n",
    "        model_path=Path(model_path),\n",
    "        db_path=Path(db_path),\n",
    "        return_cypher=True,\n",
    "        format_results=True\n",
    "    )\n",
    "    \n",
    "    if result['success']:\n",
    "        print(f\"    ‚úÖ Generated Cypher: {result['cypher']}\")\n",
    "        print(f\"    üìä Results: {result['count']} rows\")\n",
    "        if 'results' in result and result['results']:\n",
    "            # Show first few results\n",
    "            for j, row in enumerate(result['results'][:2]):\n",
    "                print(f\"      Row {j+1}: {row}\")\n",
    "            if len(result['results']) > 2:\n",
    "                print(f\"      ... and {len(result['results']) - 2} more rows\")\n",
    "    else:\n",
    "        print(f\"    ‚ùå Error: {result['error']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not detect model name, using default\n",
      "Query failed (attempt 1): Binder exception: Cannot find property role for e.\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "cannot access local variable 're' where it is not associated with a value",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/auto-graph-rag/src/auto_graph_rag/inference/query_engine.py:99\u001b[39m, in \u001b[36mQueryEngine.query\u001b[39m\u001b[34m(self, question, max_retries, temperature, return_cypher, format_results)\u001b[39m\n\u001b[32m     98\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m99\u001b[39m     results = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkuzu_adapter\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute_cypher\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcypher\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    100\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/auto-graph-rag/src/auto_graph_rag/ingestion/kuzu_adapter.py:300\u001b[39m, in \u001b[36mKuzuAdapter.execute_cypher\u001b[39m\u001b[34m(self, query)\u001b[39m\n\u001b[32m    292\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Execute a Cypher query and return results.\u001b[39;00m\n\u001b[32m    293\u001b[39m \u001b[33;03m\u001b[39;00m\n\u001b[32m    294\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    298\u001b[39m \u001b[33;03m    Query results as list of dictionaries\u001b[39;00m\n\u001b[32m    299\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m300\u001b[39m result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    302\u001b[39m \u001b[38;5;66;03m# Convert to list of dictionaries\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/auto-graph-rag/.venv/lib/python3.11/site-packages/kuzu/connection.py:131\u001b[39m, in \u001b[36mConnection.execute\u001b[39m\u001b[34m(self, query, parameters)\u001b[39m\n\u001b[32m    130\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(parameters) == \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(query, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m131\u001b[39m     query_result_internal = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_connection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    132\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mRuntimeError\u001b[39m: Binder exception: Cannot find property role for e.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mUnboundLocalError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mexecutor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mquery_with_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m        \u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdb_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdb_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_cypher\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m        \u001b[49m\u001b[43mformat_results\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/auto-graph-rag/src/auto_graph_rag/modules/query_executor.py:115\u001b[39m, in \u001b[36mQueryExecutor.query_with_model\u001b[39m\u001b[34m(self, question, model_path, db_path, model_name, return_cypher, format_results, max_retries, temperature)\u001b[39m\n\u001b[32m    108\u001b[39m query_engine = InferenceEngine(\n\u001b[32m    109\u001b[39m     model_path=\u001b[38;5;28mstr\u001b[39m(model_path),\n\u001b[32m    110\u001b[39m     kuzu_adapter=kuzu_adapter,\n\u001b[32m    111\u001b[39m     model_name=model_name\n\u001b[32m    112\u001b[39m )\n\u001b[32m    114\u001b[39m \u001b[38;5;66;03m# Execute query\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m115\u001b[39m result = \u001b[43mquery_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    116\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    117\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    119\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_cypher\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_cypher\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    120\u001b[39m \u001b[43m    \u001b[49m\u001b[43mformat_results\u001b[49m\u001b[43m=\u001b[49m\u001b[43mformat_results\u001b[49m\n\u001b[32m    121\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/auto-graph-rag/src/auto_graph_rag/inference/query_engine.py:107\u001b[39m, in \u001b[36mQueryEngine.query\u001b[39m\u001b[34m(self, question, max_retries, temperature, return_cypher, format_results)\u001b[39m\n\u001b[32m    105\u001b[39m         \u001b[38;5;66;03m# Try to fix common issues\u001b[39;00m\n\u001b[32m    106\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m attempts < max_retries - \u001b[32m1\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m107\u001b[39m             cypher = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fix_cypher_errors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcypher\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    109\u001b[39m         attempts += \u001b[32m1\u001b[39m\n\u001b[32m    111\u001b[39m \u001b[38;5;66;03m# Build response\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/auto-graph-rag/src/auto_graph_rag/inference/query_engine.py:280\u001b[39m, in \u001b[36mQueryEngine._fix_cypher_errors\u001b[39m\u001b[34m(self, cypher, error)\u001b[39m\n\u001b[32m    277\u001b[39m \u001b[38;5;66;03m# Fix property access syntax\u001b[39;00m\n\u001b[32m    278\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mproperty\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m error_lower:\n\u001b[32m    279\u001b[39m     \u001b[38;5;66;03m# Fix node.property to node['property'] syntax if needed\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m280\u001b[39m     cypher = \u001b[43mre\u001b[49m.sub(\u001b[33mr\u001b[39m\u001b[33m'\u001b[39m\u001b[33m(\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+)\u001b[39m\u001b[33m\\\u001b[39m\u001b[33m.(\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+)\u001b[39m\u001b[33m'\u001b[39m, \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\\\u001b[39m\u001b[33m1[\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\\\u001b[39m\u001b[33m2\u001b[39m\u001b[33m'\u001b[39m\u001b[33m]\u001b[39m\u001b[33m\"\u001b[39m, cypher)\n\u001b[32m    282\u001b[39m \u001b[38;5;66;03m# Fix table/label names\u001b[39;00m\n\u001b[32m    283\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mtable\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m error_lower \u001b[38;5;129;01mor\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mlabel\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m error_lower:\n\u001b[32m    284\u001b[39m     \u001b[38;5;66;03m# Try to extract the problematic label and fix case\u001b[39;00m\n",
      "\u001b[31mUnboundLocalError\u001b[39m: cannot access local variable 're' where it is not associated with a value"
     ]
    }
   ],
   "source": [
    "executor.query_with_model(\n",
    "        question=question,\n",
    "        model_path=Path(model_path),\n",
    "        db_path=Path(db_path),\n",
    "        return_cypher=True,\n",
    "        format_results=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
